{
  "os": "Linux-5.14.0-362.24.1.el9_3.0.1.x86_64-x86_64-with-glibc2.34",
  "python": "3.10.15",
  "startedAt": "2024-11-19T12:52:09.303221Z",
  "args": [
    "--model_name_or_path",
    "/bigwork/nhwpstam/argpaca/models/Meta-Llama-3-8B",
    "--data_path",
    "/bigwork/nhwpstam/argpaca/data/train/ca_finetuning_data_52365.json",
    "--bf16",
    "True",
    "--output_dir",
    "/bigwork/nhwpstam/argpaca/models/argpaca-8b-gtdata",
    "--num_train_epochs",
    "3",
    "--per_device_train_batch_size",
    "4",
    "--per_device_eval_batch_size",
    "4",
    "--gradient_accumulation_steps",
    "8",
    "--evaluation_strategy",
    "no",
    "--save_strategy",
    "steps",
    "--save_steps",
    "2000",
    "--save_total_limit",
    "1",
    "--learning_rate",
    "2e-5",
    "--weight_decay",
    "0.",
    "--warmup_ratio",
    "0.03",
    "--lr_scheduler_type",
    "cosine",
    "--logging_steps",
    "1",
    "--fsdp",
    "full_shard auto_wrap",
    "--fsdp_transformer_layer_cls_to_wrap",
    "LlamaDecoderLayer",
    "--tf32",
    "True"
  ],
  "program": "/bigwork/nhwpziet/argpaca/code/stanford_alpaca/train.py",
  "codePath": "code/stanford_alpaca/train.py",
  "git": {
    "remote": "git@github.com:timonziegenbein/argpaca.git",
    "commit": "d68c52663ba74c9ac4da744bec166e7dbe49a03c"
  },
  "root": "/bigwork/nhwpziet/argpaca/code/stanford_alpaca",
  "host": "ai-n004",
  "username": "nhwpziet",
  "executable": "/bigwork/nhwpziet/.conda/envs/alpaca_train/bin/python3.10",
  "codePathLocal": "train.py",
  "cpu_count": 128,
  "cpu_count_logical": 256,
  "gpu": "NVIDIA A100-SXM4-80GB",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "15744311296",
      "used": "5526982656"
    }
  },
  "memory": {
    "total": "1081448906752"
  },
  "cpu": {
    "count": 128,
    "countLogical": 256
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA A100-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    }
  ],
  "slurm": {
    "cluster_name": "luis",
    "conf": "/var/spool/slurmd/conf-cache/slurm.conf",
    "cpus_on_node": "8",
    "cpus_per_task": "8",
    "distribution": "pack",
    "gpus_on_node": "1",
    "gtids": "0",
    "job_account": "nhwp25179",
    "job_cpus_per_node": "8",
    "job_end_time": "1732261403",
    "job_gid": "25179",
    "job_gpus": "5",
    "job_id": "4028232",
    "job_name": "interactive",
    "job_nodelist": "ai-n004",
    "job_num_nodes": "1",
    "job_partition": "ainlp",
    "job_qos": "normal",
    "job_reservation": "ainlp_forschung",
    "job_start_time": "1732002203",
    "job_uid": "39290",
    "job_user": "nhwpziet",
    "jobid": "4028232",
    "launch_node_ipaddr": "10.7.134.3",
    "localid": "0",
    "mem_per_cpu": "10240",
    "mpi_type": "pmix",
    "nnodes": "1",
    "nodeid": "0",
    "nodelist": "ai-n004",
    "nprocs": "1",
    "ntasks": "1",
    "overlap": "1",
    "pmix_mapping_serv": "(vector,(0,1,1))",
    "pmixp_abort_agent_port": "42923",
    "prio_process": "0",
    "procid": "0",
    "pty_port": "33619",
    "pty_win_col": "106",
    "pty_win_row": "13",
    "srun_comm_host": "10.7.134.3",
    "srun_comm_port": "41473",
    "step_id": "4294967290",
    "step_launcher_port": "41473",
    "step_nodelist": "ai-n004",
    "step_num_nodes": "1",
    "step_num_tasks": "1",
    "step_tasks_per_node": "1",
    "stepid": "4294967290",
    "submit_dir": "/bigwork/nhwpstam/argpaca/data/inference",
    "submit_host": "login03.css.lan",
    "task_pid": "820716",
    "tasks_per_node": "1",
    "topology_addr": "ai-n004",
    "topology_addr_pattern": "node",
    "tres_per_task": "cpu=8"
  },
  "cudaVersion": "12.6"
}