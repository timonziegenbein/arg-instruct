{"task":"inappropriateness-detection","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.8387,"macro_recall":0.3667,"macro_f1":0.3765,"micro_precision":0.6875,"micro_recall":0.3667,"micro_f1":0.4783,"macro_precision_match":0.8387,"macro_recall_match":0.5455,"macro_f1_match":0.4872,"micro_precision_match":0.6875,"micro_recall_match":0.6875,"micro_f1_match":0.6875,"exact_matches":0.3667,"evaluatable_instances":0.5333,"rougeL":39.0879}
{"task":"toxic-emotions-detection","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.6857,"macro_recall":0.5833,"macro_f1":0.5572,"micro_precision":0.6034,"micro_recall":0.5833,"micro_f1":0.5932,"macro_precision_match":0.6857,"macro_recall_match":0.6143,"macro_f1_match":0.5662,"micro_precision_match":0.6034,"micro_recall_match":0.6034,"micro_f1_match":0.6034,"exact_matches":0.5833,"evaluatable_instances":0.9667,"rougeL":84.0832}
{"task":"missing-commitment-detection","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.565,"macro_recall":0.45,"macro_f1":0.4996,"micro_precision":0.5745,"micro_recall":0.45,"micro_f1":0.5047,"macro_precision_match":0.565,"macro_recall_match":0.5667,"macro_f1_match":0.5648,"micro_precision_match":0.5745,"micro_recall_match":0.5745,"micro_f1_match":0.5745,"exact_matches":0.45,"evaluatable_instances":0.7833,"rougeL":70.1075}
{"task":"missing-intelligibility-detection","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.68,"macro_recall":0.6,"macro_f1":0.55,"micro_precision":0.6,"micro_recall":0.6,"micro_f1":0.6,"macro_precision_match":0.68,"macro_recall_match":0.6,"macro_f1_match":0.55,"micro_precision_match":0.6,"micro_recall_match":0.6,"micro_f1_match":0.6,"exact_matches":0.6,"evaluatable_instances":1.0,"rougeL":86.6667}
{"task":"other-inappropriateness-detection","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.2453,"macro_recall":0.4815,"macro_f1":0.325,"micro_precision":0.4815,"micro_recall":0.4815,"micro_f1":0.4815,"macro_precision_match":0.2453,"macro_recall_match":0.4815,"macro_f1_match":0.325,"micro_precision_match":0.4815,"micro_recall_match":0.4815,"micro_f1_match":0.4815,"exact_matches":0.4815,"evaluatable_instances":1.0,"rougeL":95.2862}
{"task":"excessive-intensity-detection","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.375,"macro_recall":0.15,"macro_f1":0.2143,"micro_precision":0.75,"micro_recall":0.15,"micro_f1":0.25,"macro_precision_match":0.375,"macro_recall_match":0.5,"macro_f1_match":0.4286,"micro_precision_match":0.75,"micro_recall_match":0.75,"micro_f1_match":0.75,"exact_matches":0.15,"evaluatable_instances":0.2,"rougeL":70.6076}
{"task":"emotional-deception-detection","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.0,"macro_recall":0.0,"macro_f1":0.0,"micro_precision":0.0,"micro_recall":0.0,"micro_f1":0.0,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":46.9171}
{"task":"missing-seriousness-detection","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.5825,"macro_recall":0.5333,"macro_f1":0.4691,"micro_precision":0.5517,"micro_recall":0.5333,"micro_f1":0.5424,"macro_precision_match":0.5825,"macro_recall_match":0.5393,"macro_f1_match":0.4764,"micro_precision_match":0.5517,"micro_recall_match":0.5517,"micro_f1_match":0.5517,"exact_matches":0.5333,"evaluatable_instances":0.9667,"rougeL":82.6107}
{"task":"missing-openness-detection","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.6912,"macro_recall":0.55,"macro_f1":0.4846,"micro_precision":0.5789,"micro_recall":0.55,"micro_f1":0.5641,"macro_precision_match":0.6912,"macro_recall_match":0.572,"macro_f1_match":0.4971,"micro_precision_match":0.5789,"micro_recall_match":0.5789,"micro_f1_match":0.5789,"exact_matches":0.55,"evaluatable_instances":0.95,"rougeL":82.2417}
{"task":"unclear-meaning-detection","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.25,"macro_recall_match":0.5,"macro_f1_match":0.3333,"micro_precision_match":0.5,"micro_recall_match":0.5,"micro_f1_match":0.5,"exact_matches":0.5,"evaluatable_instances":1.0,"rougeL":75.0}
{"task":"missing-relevance-detection","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.5923,"macro_recall":0.5167,"macro_f1":0.3978,"micro_precision":0.5254,"micro_recall":0.5167,"micro_f1":0.521,"macro_precision_match":0.5923,"macro_recall_match":0.5178,"macro_f1_match":0.3997,"micro_precision_match":0.5254,"micro_recall_match":0.5254,"micro_f1_match":0.5254,"exact_matches":0.5167,"evaluatable_instances":0.9833,"rougeL":78.5088}
{"task":"confusing-reasoning-detection","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.2857,"macro_recall":0.0667,"macro_f1":0.1081,"micro_precision":0.5714,"micro_recall":0.0667,"micro_f1":0.1194,"macro_precision_match":0.2857,"macro_recall_match":0.5,"macro_f1_match":0.3636,"micro_precision_match":0.5714,"micro_recall_match":0.5714,"micro_f1_match":0.5714,"exact_matches":0.0667,"evaluatable_instances":0.1167,"rougeL":48.1116}
{"task":"detrimental-orthography-detection","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.25,"macro_recall_match":0.5,"macro_f1_match":0.3333,"micro_precision_match":0.5,"micro_recall_match":0.5,"micro_f1_match":0.5,"exact_matches":0.5,"evaluatable_instances":1.0,"rougeL":75.0}
{"task":"reason-unclassified-detection","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.0,"macro_recall":0.0,"macro_f1":0.0,"micro_precision":0.0,"micro_recall":0.0,"micro_f1":0.0,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":67.0833}
{"task":"key-point-matching","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.0,"macro_recall":0.0,"macro_f1":0.0,"micro_precision":0.0,"micro_recall":0.0,"micro_f1":0.0,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":8.1561}
{"task":"same-side-stance-classification","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.5357,"macro_recall":0.15,"macro_f1":0.2131,"micro_precision":0.5625,"micro_recall":0.15,"micro_f1":0.2368,"macro_precision_match":0.5357,"macro_recall_match":0.5159,"macro_f1_match":0.4589,"micro_precision_match":0.5625,"micro_recall_match":0.5625,"micro_f1_match":0.5625,"exact_matches":0.15,"evaluatable_instances":0.2667,"rougeL":57.8637}
{"task":"novelty-classification","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.0,"macro_recall":0.0,"macro_f1":0.0,"micro_precision":0.0,"micro_recall":0.0,"micro_f1":0.0,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":4.484}
{"task":"validity-classification","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.0,"macro_recall":0.0,"macro_f1":0.0,"micro_precision":0.0,"micro_recall":0.0,"micro_f1":0.0,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":10.5931}
{"task":"relative-novelty-classification","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.0,"macro_recall":0.0,"macro_f1":0.0,"micro_precision":0.0,"micro_recall":0.0,"micro_f1":0.0,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":4.916}
{"task":"relative-validity-classification","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.0,"macro_recall":0.0,"macro_f1":0.0,"micro_precision":0.0,"micro_recall":0.0,"micro_f1":0.0,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":1.9113}
{"task":"content-scoring","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.0238,"macro_recall":0.1429,"macro_f1":0.0408,"micro_precision":0.1429,"micro_recall":0.1429,"micro_f1":0.1429,"macro_precision_match":0.0238,"macro_recall_match":0.1429,"macro_f1_match":0.0408,"micro_precision_match":0.1429,"micro_recall_match":0.1429,"micro_f1_match":0.1429,"exact_matches":0.1429,"evaluatable_instances":1.0,"rougeL":38.0952}
{"task":"identifying-argumentative-relations","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.0,"macro_recall":0.0,"macro_f1":0.0,"micro_precision":0.0,"micro_recall":0.0,"micro_f1":0.0,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":1.0853}
{"task":"stance-recognition","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.4355,"macro_recall":0.45,"macro_f1":0.4426,"micro_precision":0.871,"micro_recall":0.45,"micro_f1":0.5934,"macro_precision_match":0.4355,"macro_recall_match":0.5,"macro_f1_match":0.4655,"micro_precision_match":0.871,"micro_recall_match":0.871,"micro_f1_match":0.871,"exact_matches":0.45,"evaluatable_instances":0.5167,"rougeL":52.037}
{"task":"inappropriateness-detection","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.62,"macro_recall":0.5667,"macro_f1":0.5125,"micro_precision":0.5667,"micro_recall":0.5667,"micro_f1":0.5667,"macro_precision_match":0.5064,"macro_recall_match":0.5043,"macro_f1_match":0.3914,"micro_precision_match":0.4062,"micro_recall_match":0.4062,"micro_f1_match":0.4062,"exact_matches":0.2167,"evaluatable_instances":0.5333,"rougeL":56.6667}
{"task":"toxic-emotions-detection","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.5857,"macro_recall":0.5833,"macro_f1":0.5804,"micro_precision":0.5833,"micro_recall":0.5833,"micro_f1":0.5833,"macro_precision_match":0.6118,"macro_recall_match":0.6071,"macro_f1_match":0.6005,"micro_precision_match":0.6034,"micro_recall_match":0.6034,"micro_f1_match":0.6034,"exact_matches":0.5833,"evaluatable_instances":0.9667,"rougeL":86.1111}
{"task":"missing-commitment-detection","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.2021,"macro_recall_match":0.5,"macro_f1_match":0.2879,"micro_precision_match":0.4043,"micro_recall_match":0.4043,"micro_f1_match":0.4043,"exact_matches":0.3167,"evaluatable_instances":0.7833,"rougeL":83.3333}
{"task":"missing-intelligibility-detection","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.25,"macro_recall_match":0.5,"macro_f1_match":0.3333,"micro_precision_match":0.5,"micro_recall_match":0.5,"micro_f1_match":0.5,"exact_matches":0.5,"evaluatable_instances":1.0,"rougeL":83.3333}
{"task":"other-inappropriateness-detection","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.635,"macro_recall":0.537,"macro_f1":0.4344,"micro_precision":0.537,"micro_recall":0.537,"micro_f1":0.537,"macro_precision_match":0.635,"macro_recall_match":0.537,"macro_f1_match":0.4344,"micro_precision_match":0.537,"micro_recall_match":0.537,"micro_f1_match":0.537,"exact_matches":0.537,"evaluatable_instances":1.0,"rougeL":95.7912}
{"task":"excessive-intensity-detection","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.375,"macro_recall_match":0.5,"macro_f1_match":0.4286,"micro_precision_match":0.75,"micro_recall_match":0.75,"micro_f1_match":0.75,"exact_matches":0.15,"evaluatable_instances":0.2,"rougeL":75.0}
{"task":"emotional-deception-detection","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.4282,"macro_recall":0.4333,"macro_f1":0.4231,"micro_precision":0.4333,"micro_recall":0.4333,"micro_f1":0.4333,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":91.9048}
{"task":"missing-seriousness-detection","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.2414,"macro_recall_match":0.5,"macro_f1_match":0.3256,"micro_precision_match":0.4828,"micro_recall_match":0.4828,"micro_f1_match":0.4828,"exact_matches":0.4667,"evaluatable_instances":0.9667,"rougeL":83.3333}
{"task":"missing-openness-detection","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.2456,"macro_recall_match":0.5,"macro_f1_match":0.3294,"micro_precision_match":0.4912,"micro_recall_match":0.4912,"micro_f1_match":0.4912,"exact_matches":0.4667,"evaluatable_instances":0.95,"rougeL":83.3333}
{"task":"unclear-meaning-detection","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.25,"macro_recall_match":0.5,"macro_f1_match":0.3333,"micro_precision_match":0.5,"micro_recall_match":0.5,"micro_f1_match":0.5,"exact_matches":0.5,"evaluatable_instances":1.0,"rougeL":75.0}
{"task":"missing-relevance-detection","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.2458,"macro_recall_match":0.5,"macro_f1_match":0.3295,"micro_precision_match":0.4915,"micro_recall_match":0.4915,"micro_f1_match":0.4915,"exact_matches":0.4833,"evaluatable_instances":0.9833,"rougeL":78.5714}
{"task":"confusing-reasoning-detection","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.2857,"macro_recall_match":0.5,"macro_f1_match":0.3636,"micro_precision_match":0.5714,"micro_recall_match":0.5714,"micro_f1_match":0.5714,"exact_matches":0.0667,"evaluatable_instances":0.1167,"rougeL":75.0}
{"task":"detrimental-orthography-detection","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.25,"macro_recall_match":0.5,"macro_f1_match":0.3333,"micro_precision_match":0.5,"micro_recall_match":0.5,"micro_f1_match":0.5,"exact_matches":0.5,"evaluatable_instances":1.0,"rougeL":75.0}
{"task":"reason-unclassified-detection","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":90.0}
{"task":"key-point-matching","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.5,"macro_recall":0.5,"macro_f1":0.3608,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":50.0}
{"task":"same-side-stance-classification","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.4479,"macro_recall":0.4667,"macro_f1":0.4139,"micro_precision":0.4667,"micro_recall":0.4667,"micro_f1":0.4667,"macro_precision_match":0.3651,"macro_recall_match":0.3651,"macro_f1_match":0.3651,"micro_precision_match":0.375,"micro_recall_match":0.375,"micro_f1_match":0.375,"exact_matches":0.1,"evaluatable_instances":0.2667,"rougeL":82.2222}
{"task":"novelty-classification","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":50.0}
{"task":"validity-classification","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.7941,"macro_recall":0.65,"macro_f1":0.6011,"micro_precision":0.65,"micro_recall":0.65,"micro_f1":0.65,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":65.0}
{"task":"relative-novelty-classification","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.1111,"macro_recall":0.3333,"macro_f1":0.1667,"micro_precision":0.3333,"micro_recall":0.3333,"micro_f1":0.3333,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":33.3333}
{"task":"relative-validity-classification","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.1111,"macro_recall":0.3333,"macro_f1":0.1667,"micro_precision":0.3333,"micro_recall":0.3333,"micro_f1":0.3333,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":33.3333}
{"task":"content-scoring","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.0204,"macro_recall":0.1429,"macro_f1":0.0357,"micro_precision":0.1429,"micro_recall":0.1429,"micro_f1":0.1429,"macro_precision_match":0.0204,"macro_recall_match":0.1429,"macro_f1_match":0.0357,"micro_precision_match":0.1429,"micro_recall_match":0.1429,"micro_f1_match":0.1429,"exact_matches":0.1429,"evaluatable_instances":1.0,"rougeL":38.0952}
{"task":"identifying-argumentative-relations","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":50.0}
{"task":"stance-recognition","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.0645,"macro_recall_match":0.5,"macro_f1_match":0.1143,"micro_precision_match":0.129,"micro_recall_match":0.129,"micro_f1_match":0.129,"exact_matches":0.0667,"evaluatable_instances":0.5167,"rougeL":50.0}
{"task":"inappropriateness-detection","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.7291,"macro_recall":0.7167,"macro_f1":0.7128,"micro_precision":0.7167,"micro_recall":0.7167,"micro_f1":0.7167,"macro_precision_match":0.5893,"macro_recall_match":0.5433,"macro_f1_match":0.5211,"micro_precision_match":0.6562,"micro_recall_match":0.6562,"micro_f1_match":0.6562,"exact_matches":0.35,"evaluatable_instances":0.5333,"rougeL":71.6667}
{"task":"toxic-emotions-detection","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.2414,"macro_recall_match":0.5,"macro_f1_match":0.3256,"micro_precision_match":0.4828,"micro_recall_match":0.4828,"micro_f1_match":0.4828,"exact_matches":0.4667,"evaluatable_instances":0.9667,"rougeL":83.3333}
{"task":"missing-commitment-detection","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.402,"macro_recall":0.45,"macro_f1":0.3732,"micro_precision":0.45,"micro_recall":0.45,"micro_f1":0.45,"macro_precision_match":0.3464,"macro_recall_match":0.4192,"macro_f1_match":0.362,"micro_precision_match":0.4894,"micro_recall_match":0.4894,"micro_f1_match":0.4894,"exact_matches":0.3833,"evaluatable_instances":0.7833,"rougeL":81.6667}
{"task":"missing-intelligibility-detection","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.4455,"macro_recall":0.4833,"macro_f1":0.3748,"micro_precision":0.4833,"micro_recall":0.4833,"micro_f1":0.4833,"macro_precision_match":0.4455,"macro_recall_match":0.4833,"macro_f1_match":0.3748,"micro_precision_match":0.4833,"micro_recall_match":0.4833,"micro_f1_match":0.4833,"exact_matches":0.4833,"evaluatable_instances":1.0,"rougeL":82.7778}
{"task":"other-inappropriateness-detection","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.25,"macro_recall_match":0.5,"macro_f1_match":0.3333,"micro_precision_match":0.5,"micro_recall_match":0.5,"micro_f1_match":0.5,"exact_matches":0.5,"evaluatable_instances":1.0,"rougeL":95.4545}
{"task":"excessive-intensity-detection","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.375,"macro_recall_match":0.5,"macro_f1_match":0.4286,"micro_precision_match":0.75,"micro_recall_match":0.75,"micro_f1_match":0.75,"exact_matches":0.15,"evaluatable_instances":0.2,"rougeL":75.0}
{"task":"emotional-deception-detection","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.2458,"macro_recall":0.4833,"macro_f1":0.3258,"micro_precision":0.4833,"micro_recall":0.4833,"micro_f1":0.4833,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":92.619}
{"task":"missing-seriousness-detection","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.2458,"macro_recall":0.4833,"macro_f1":0.3258,"micro_precision":0.4833,"micro_recall":0.4833,"micro_f1":0.4833,"macro_precision_match":0.2544,"macro_recall_match":0.4833,"macro_f1_match":0.3333,"micro_precision_match":0.5,"micro_recall_match":0.5,"micro_f1_match":0.5,"exact_matches":0.4833,"evaluatable_instances":0.9667,"rougeL":82.7778}
{"task":"missing-openness-detection","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.2544,"macro_recall_match":0.5,"macro_f1_match":0.3372,"micro_precision_match":0.5088,"micro_recall_match":0.5088,"micro_f1_match":0.5088,"exact_matches":0.4833,"evaluatable_instances":0.95,"rougeL":83.3333}
{"task":"unclear-meaning-detection","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.25,"macro_recall_match":0.5,"macro_f1_match":0.3333,"micro_precision_match":0.5,"micro_recall_match":0.5,"micro_f1_match":0.5,"exact_matches":0.5,"evaluatable_instances":1.0,"rougeL":75.0}
{"task":"missing-relevance-detection","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.2458,"macro_recall":0.4833,"macro_f1":0.3258,"micro_precision":0.4833,"micro_recall":0.4833,"micro_f1":0.4833,"macro_precision_match":0.25,"macro_recall_match":0.4833,"macro_f1_match":0.3295,"micro_precision_match":0.4915,"micro_recall_match":0.4915,"micro_f1_match":0.4915,"exact_matches":0.4833,"evaluatable_instances":0.9833,"rougeL":77.8571}
{"task":"confusing-reasoning-detection","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.2857,"macro_recall_match":0.5,"macro_f1_match":0.3636,"micro_precision_match":0.5714,"micro_recall_match":0.5714,"micro_f1_match":0.5714,"exact_matches":0.0667,"evaluatable_instances":0.1167,"rougeL":75.0}
{"task":"detrimental-orthography-detection","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.25,"macro_recall_match":0.5,"macro_f1_match":0.3333,"micro_precision_match":0.5,"micro_recall_match":0.5,"micro_f1_match":0.5,"exact_matches":0.5,"evaluatable_instances":1.0,"rougeL":75.0}
{"task":"reason-unclassified-detection","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.2273,"macro_recall":0.4167,"macro_f1":0.2941,"micro_precision":0.4167,"micro_recall":0.4167,"micro_f1":0.4167,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":88.3333}
{"task":"key-point-matching","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.3923,"macro_recall":0.4,"macro_f1":0.3891,"micro_precision":0.4,"micro_recall":0.4,"micro_f1":0.4,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":40.0}
{"task":"same-side-stance-classification","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.5,"macro_recall":0.5,"macro_f1":0.4857,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.5357,"macro_recall_match":0.5159,"macro_f1_match":0.4589,"micro_precision_match":0.5625,"micro_recall_match":0.5625,"micro_f1_match":0.5625,"exact_matches":0.15,"evaluatable_instances":0.2667,"rougeL":83.3333}
{"task":"novelty-classification","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.4722,"macro_recall":0.4833,"macro_f1":0.4257,"micro_precision":0.4833,"micro_recall":0.4833,"micro_f1":0.4833,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":48.3333}
{"task":"validity-classification","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.8488,"macro_recall":0.7833,"macro_f1":0.7727,"micro_precision":0.7833,"micro_recall":0.7833,"micro_f1":0.7833,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":78.3333}
{"task":"relative-novelty-classification","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.1964,"macro_recall":0.3333,"macro_f1":0.1944,"micro_precision":0.3333,"micro_recall":0.3333,"micro_f1":0.3333,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":33.3333}
{"task":"relative-validity-classification","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.1861,"macro_recall":0.2833,"macro_f1":0.2217,"micro_precision":0.2833,"micro_recall":0.2833,"micro_f1":0.2833,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":28.3333}
{"task":"content-scoring","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.0238,"macro_recall":0.1429,"macro_f1":0.0408,"micro_precision":0.1429,"micro_recall":0.1429,"micro_f1":0.1429,"macro_precision_match":0.0238,"macro_recall_match":0.1429,"macro_f1_match":0.0408,"micro_precision_match":0.1429,"micro_recall_match":0.1429,"micro_f1_match":0.1429,"exact_matches":0.1429,"evaluatable_instances":1.0,"rougeL":38.0952}
{"task":"identifying-argumentative-relations","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":50.0}
{"task":"stance-recognition","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.7679,"macro_recall":0.5667,"macro_f1":0.4665,"micro_precision":0.5667,"micro_recall":0.5667,"micro_f1":0.5667,"macro_precision_match":0.5741,"macro_recall_match":0.5741,"macro_f1_match":0.2581,"micro_precision_match":0.2581,"micro_recall_match":0.2581,"micro_f1_match":0.2581,"exact_matches":0.1333,"evaluatable_instances":0.5167,"rougeL":56.6667}
{"task":"inappropriateness-detection","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.5,"macro_recall":0.5,"macro_f1":0.4994,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.5938,"macro_recall_match":0.6039,"macro_f1_match":0.5836,"micro_precision_match":0.5938,"micro_recall_match":0.5938,"micro_f1_match":0.5938,"exact_matches":0.3167,"evaluatable_instances":0.5333,"rougeL":50.0}
{"task":"toxic-emotions-detection","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.5501,"macro_recall":0.55,"macro_f1":0.5499,"micro_precision":0.55,"micro_recall":0.55,"micro_f1":0.55,"macro_precision_match":0.5512,"macro_recall_match":0.5512,"macro_f1_match":0.5512,"micro_precision_match":0.5517,"micro_recall_match":0.5517,"micro_f1_match":0.5517,"exact_matches":0.5333,"evaluatable_instances":0.9667,"rougeL":85.0}
{"task":"missing-commitment-detection","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.6667,"macro_recall":0.6667,"macro_f1":0.6667,"micro_precision":0.6667,"micro_recall":0.6667,"micro_f1":0.6667,"macro_precision_match":0.6511,"macro_recall_match":0.6551,"macro_f1_match":0.6519,"micro_precision_match":0.6596,"micro_recall_match":0.6596,"micro_f1_match":0.6596,"exact_matches":0.5167,"evaluatable_instances":0.7833,"rougeL":88.8889}
{"task":"missing-intelligibility-detection","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.5168,"macro_recall":0.5167,"macro_f1":0.5155,"micro_precision":0.5167,"micro_recall":0.5167,"micro_f1":0.5167,"macro_precision_match":0.5168,"macro_recall_match":0.5167,"macro_f1_match":0.5155,"micro_precision_match":0.5167,"micro_recall_match":0.5167,"micro_f1_match":0.5167,"exact_matches":0.5167,"evaluatable_instances":1.0,"rougeL":83.8889}
{"task":"other-inappropriateness-detection","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.4416,"macro_recall":0.4444,"macro_f1":0.4375,"micro_precision":0.4444,"micro_recall":0.4444,"micro_f1":0.4444,"macro_precision_match":0.4416,"macro_recall_match":0.4444,"macro_f1_match":0.4375,"micro_precision_match":0.4444,"micro_recall_match":0.4444,"micro_f1_match":0.4444,"exact_matches":0.4444,"evaluatable_instances":1.0,"rougeL":94.9495}
{"task":"excessive-intensity-detection","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.4486,"macro_recall":0.45,"macro_f1":0.4462,"micro_precision":0.45,"micro_recall":0.45,"micro_f1":0.45,"macro_precision_match":0.3125,"macro_recall_match":0.2778,"macro_f1_match":0.2941,"micro_precision_match":0.4167,"micro_recall_match":0.4167,"micro_f1_match":0.4167,"exact_matches":0.0833,"evaluatable_instances":0.2,"rougeL":72.5}
{"task":"emotional-deception-detection","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.4321,"macro_recall":0.4333,"macro_f1":0.4308,"micro_precision":0.4333,"micro_recall":0.4333,"micro_f1":0.4333,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":91.9048}
{"task":"missing-seriousness-detection","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.6674,"macro_recall":0.6667,"macro_f1":0.6663,"micro_precision":0.6667,"micro_recall":0.6667,"micro_f1":0.6667,"macro_precision_match":0.672,"macro_recall_match":0.6714,"macro_f1_match":0.6715,"micro_precision_match":0.6724,"micro_recall_match":0.6724,"micro_f1_match":0.6724,"exact_matches":0.65,"evaluatable_instances":0.9667,"rougeL":88.8889}
{"task":"missing-openness-detection","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.5176,"macro_recall":0.5167,"macro_f1":0.51,"micro_precision":0.5167,"micro_recall":0.5167,"micro_f1":0.5167,"macro_precision_match":0.4881,"macro_recall_match":0.4889,"macro_f1_match":0.481,"micro_precision_match":0.4912,"micro_recall_match":0.4912,"micro_f1_match":0.4912,"exact_matches":0.4667,"evaluatable_instances":0.95,"rougeL":83.8889}
{"task":"unclear-meaning-detection","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.4321,"macro_recall":0.4333,"macro_f1":0.4308,"micro_precision":0.4333,"micro_recall":0.4333,"micro_f1":0.4333,"macro_precision_match":0.4321,"macro_recall_match":0.4333,"macro_f1_match":0.4308,"micro_precision_match":0.4333,"micro_recall_match":0.4333,"micro_f1_match":0.4333,"exact_matches":0.4333,"evaluatable_instances":1.0,"rougeL":71.6667}
{"task":"missing-relevance-detection","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.5505,"macro_recall":0.55,"macro_f1":0.5489,"micro_precision":0.55,"micro_recall":0.55,"micro_f1":0.55,"macro_precision_match":0.5612,"macro_recall_match":0.5603,"macro_f1_match":0.5582,"micro_precision_match":0.5593,"micro_recall_match":0.5593,"micro_f1_match":0.5593,"exact_matches":0.55,"evaluatable_instances":0.9833,"rougeL":80.7143}
{"task":"confusing-reasoning-detection","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.5347,"macro_recall":0.5333,"macro_f1":0.5286,"micro_precision":0.5333,"micro_recall":0.5333,"micro_f1":0.5333,"macro_precision_match":0.55,"macro_recall_match":0.5417,"macro_f1_match":0.5333,"micro_precision_match":0.5714,"micro_recall_match":0.5714,"micro_f1_match":0.5714,"exact_matches":0.0667,"evaluatable_instances":0.1167,"rougeL":76.6667}
{"task":"detrimental-orthography-detection","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.4464,"macro_recall":0.4464,"macro_f1":0.4463,"micro_precision":0.4464,"micro_recall":0.4464,"micro_f1":0.4464,"macro_precision_match":0.4464,"macro_recall_match":0.4464,"macro_f1_match":0.4463,"micro_precision_match":0.4464,"micro_recall_match":0.4464,"micro_f1_match":0.4464,"exact_matches":0.4464,"evaluatable_instances":1.0,"rougeL":72.3214}
{"task":"reason-unclassified-detection","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.5417,"macro_recall":0.5417,"macro_f1":0.5417,"micro_precision":0.5417,"micro_recall":0.5417,"micro_f1":0.5417,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":90.8333}
{"task":"key-point-matching","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.4499,"macro_recall":0.45,"macro_f1":0.4498,"micro_precision":0.45,"micro_recall":0.45,"micro_f1":0.45,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":45.0}
{"task":"same-side-stance-classification","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.4832,"macro_recall":0.4833,"macro_f1":0.482,"micro_precision":0.4833,"micro_recall":0.4833,"micro_f1":0.4833,"macro_precision_match":0.6349,"macro_recall_match":0.6349,"macro_f1_match":0.625,"micro_precision_match":0.625,"micro_recall_match":0.625,"micro_f1_match":0.625,"exact_matches":0.1667,"evaluatable_instances":0.2667,"rougeL":82.7778}
{"task":"novelty-classification","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.5679,"macro_recall":0.5667,"macro_f1":0.5647,"micro_precision":0.5667,"micro_recall":0.5667,"micro_f1":0.5667,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":56.6667}
{"task":"validity-classification","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.4158,"macro_recall":0.4167,"macro_f1":0.4152,"micro_precision":0.4167,"micro_recall":0.4167,"micro_f1":0.4167,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":41.6667}
{"task":"relative-novelty-classification","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.2973,"macro_recall":0.3,"macro_f1":0.2963,"micro_precision":0.3,"micro_recall":0.3,"micro_f1":0.3,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":30.0}
{"task":"relative-validity-classification","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.319,"macro_recall":0.3167,"macro_f1":0.3173,"micro_precision":0.3167,"micro_recall":0.3167,"micro_f1":0.3167,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":31.6667}
{"task":"content-scoring","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.0383,"macro_recall":0.0571,"macro_f1":0.0458,"micro_precision":0.0571,"micro_recall":0.0571,"micro_f1":0.0571,"macro_precision_match":0.0383,"macro_recall_match":0.0571,"macro_f1_match":0.0458,"micro_precision_match":0.0571,"micro_recall_match":0.0571,"micro_f1_match":0.0571,"exact_matches":0.0571,"evaluatable_instances":1.0,"rougeL":30.0}
{"task":"identifying-argumentative-relations","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.4667,"macro_recall":0.4667,"macro_f1":0.4667,"micro_precision":0.4667,"micro_recall":0.4667,"micro_f1":0.4667,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":46.6667}
{"task":"stance-recognition","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.4471,"macro_recall":0.45,"macro_f1":0.4424,"micro_precision":0.45,"micro_recall":0.45,"micro_f1":0.45,"macro_precision_match":0.5295,"macro_recall_match":0.5602,"macro_f1_match":0.3882,"micro_precision_match":0.4194,"micro_recall_match":0.4194,"micro_f1_match":0.4194,"exact_matches":0.2167,"evaluatable_instances":0.5167,"rougeL":45.0}
{"task":"inappropriateness-detection","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.7257,"macro_recall":0.6833,"macro_f1":0.6677,"micro_precision":0.6833,"micro_recall":0.6833,"micro_f1":0.6833,"macro_precision_match":0.8387,"macro_recall_match":0.5455,"macro_f1_match":0.4872,"micro_precision_match":0.6875,"micro_recall_match":0.6875,"micro_f1_match":0.6875,"exact_matches":0.3667,"evaluatable_instances":0.5333,"rougeL":68.3333}
{"task":"toxic-emotions-detection","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.6227,"macro_recall":0.5833,"macro_f1":0.547,"micro_precision":0.5833,"micro_recall":0.5833,"micro_f1":0.5833,"macro_precision_match":0.6857,"macro_recall_match":0.6143,"macro_f1_match":0.5662,"micro_precision_match":0.6034,"micro_recall_match":0.6034,"micro_f1_match":0.6034,"exact_matches":0.5833,"evaluatable_instances":0.9667,"rougeL":86.1111}
{"task":"missing-commitment-detection","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.6357,"macro_recall":0.6333,"macro_f1":0.6317,"micro_precision":0.6333,"micro_recall":0.6333,"micro_f1":0.6333,"macro_precision_match":0.565,"macro_recall_match":0.5667,"macro_f1_match":0.5648,"micro_precision_match":0.5745,"micro_recall_match":0.5745,"micro_f1_match":0.5745,"exact_matches":0.45,"evaluatable_instances":0.7833,"rougeL":87.7778}
{"task":"missing-intelligibility-detection","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.68,"macro_recall":0.6,"macro_f1":0.55,"micro_precision":0.6,"micro_recall":0.6,"micro_f1":0.6,"macro_precision_match":0.68,"macro_recall_match":0.6,"macro_f1_match":0.55,"micro_precision_match":0.6,"micro_recall_match":0.6,"micro_f1_match":0.6,"exact_matches":0.6,"evaluatable_instances":1.0,"rougeL":86.6667}
{"task":"other-inappropriateness-detection","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.2453,"macro_recall":0.4815,"macro_f1":0.325,"micro_precision":0.4815,"micro_recall":0.4815,"micro_f1":0.4815,"macro_precision_match":0.2453,"macro_recall_match":0.4815,"macro_f1_match":0.325,"micro_precision_match":0.4815,"micro_recall_match":0.4815,"micro_f1_match":0.4815,"exact_matches":0.4815,"evaluatable_instances":1.0,"rougeL":95.2862}
{"task":"excessive-intensity-detection","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.5877,"macro_recall":0.5167,"macro_f1":0.3939,"micro_precision":0.5167,"micro_recall":0.5167,"micro_f1":0.5167,"macro_precision_match":0.375,"macro_recall_match":0.5,"macro_f1_match":0.4286,"micro_precision_match":0.75,"micro_recall_match":0.75,"micro_f1_match":0.75,"exact_matches":0.15,"evaluatable_instances":0.2,"rougeL":75.8333}
{"task":"emotional-deception-detection","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.2458,"macro_recall":0.4833,"macro_f1":0.3258,"micro_precision":0.4833,"micro_recall":0.4833,"micro_f1":0.4833,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":92.619}
{"task":"missing-seriousness-detection","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.598,"macro_recall":0.55,"macro_f1":0.4872,"micro_precision":0.55,"micro_recall":0.55,"micro_f1":0.55,"macro_precision_match":0.5825,"macro_recall_match":0.5393,"macro_f1_match":0.4764,"micro_precision_match":0.5517,"micro_recall_match":0.5517,"micro_f1_match":0.5517,"exact_matches":0.5333,"evaluatable_instances":0.9667,"rougeL":85.0}
{"task":"missing-openness-detection","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.7022,"macro_recall":0.5833,"macro_f1":0.5116,"micro_precision":0.5833,"micro_recall":0.5833,"micro_f1":0.5833,"macro_precision_match":0.6912,"macro_recall_match":0.572,"macro_f1_match":0.4971,"micro_precision_match":0.5789,"micro_recall_match":0.5789,"micro_f1_match":0.5789,"exact_matches":0.55,"evaluatable_instances":0.95,"rougeL":86.1111}
{"task":"unclear-meaning-detection","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.25,"macro_recall_match":0.5,"macro_f1_match":0.3333,"micro_precision_match":0.5,"micro_recall_match":0.5,"micro_f1_match":0.5,"exact_matches":0.5,"evaluatable_instances":1.0,"rougeL":75.0}
{"task":"missing-relevance-detection","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.5877,"macro_recall":0.5167,"macro_f1":0.3939,"micro_precision":0.5167,"micro_recall":0.5167,"micro_f1":0.5167,"macro_precision_match":0.5923,"macro_recall_match":0.5178,"macro_f1_match":0.3997,"micro_precision_match":0.5254,"micro_recall_match":0.5254,"micro_f1_match":0.5254,"exact_matches":0.5167,"evaluatable_instances":0.9833,"rougeL":79.2857}
{"task":"confusing-reasoning-detection","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.2857,"macro_recall_match":0.5,"macro_f1_match":0.3636,"micro_precision_match":0.5714,"micro_recall_match":0.5714,"micro_f1_match":0.5714,"exact_matches":0.0667,"evaluatable_instances":0.1167,"rougeL":75.0}
{"task":"detrimental-orthography-detection","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.25,"macro_recall_match":0.5,"macro_f1_match":0.3333,"micro_precision_match":0.5,"micro_recall_match":0.5,"micro_f1_match":0.5,"exact_matches":0.5,"evaluatable_instances":1.0,"rougeL":75.0}
{"task":"reason-unclassified-detection","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":90.0}
{"task":"key-point-matching","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.4206,"macro_recall":0.4333,"macro_f1":0.4097,"micro_precision":0.4333,"micro_recall":0.4333,"micro_f1":0.4333,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":43.3333}
{"task":"same-side-stance-classification","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.5857,"macro_recall":0.5833,"macro_f1":0.5804,"micro_precision":0.5833,"micro_recall":0.5833,"micro_f1":0.5833,"macro_precision_match":0.5357,"macro_recall_match":0.5159,"macro_f1_match":0.4589,"micro_precision_match":0.5625,"micro_recall_match":0.5625,"micro_f1_match":0.5625,"exact_matches":0.15,"evaluatable_instances":0.2667,"rougeL":86.1111}
{"task":"novelty-classification","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.5736,"macro_recall":0.55,"macro_f1":0.5107,"micro_precision":0.55,"micro_recall":0.55,"micro_f1":0.55,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":55.0}
{"task":"validity-classification","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.8571,"macro_recall":0.8,"macro_f1":0.7917,"micro_precision":0.8,"micro_recall":0.8,"micro_f1":0.8,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":80.0}
{"task":"relative-novelty-classification","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.2222,"macro_recall":0.3333,"macro_f1":0.2286,"micro_precision":0.3333,"micro_recall":0.3333,"micro_f1":0.3333,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":33.3333}
{"task":"relative-validity-classification","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.1878,"macro_recall":0.2833,"macro_f1":0.2249,"micro_precision":0.2833,"micro_recall":0.2833,"micro_f1":0.2833,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":28.3333}
{"task":"content-scoring","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.0238,"macro_recall":0.1429,"macro_f1":0.0408,"micro_precision":0.1429,"micro_recall":0.1429,"micro_f1":0.1429,"macro_precision_match":0.0238,"macro_recall_match":0.1429,"macro_f1_match":0.0408,"micro_precision_match":0.1429,"micro_recall_match":0.1429,"micro_f1_match":0.1429,"exact_matches":0.1429,"evaluatable_instances":1.0,"rougeL":38.0952}
{"task":"identifying-argumentative-relations","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.25,"macro_recall":0.5,"macro_f1":0.3333,"micro_precision":0.5,"micro_recall":0.5,"micro_f1":0.5,"macro_precision_match":0.0,"macro_recall_match":0.0,"macro_f1_match":0.0,"micro_precision_match":0.0,"micro_recall_match":0.0,"micro_f1_match":0.0,"exact_matches":0.0,"evaluatable_instances":0.0,"rougeL":50.0}
{"task":"stance-recognition","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.8,"macro_recall":0.8,"macro_f1":0.8,"micro_precision":0.8,"micro_recall":0.8,"micro_f1":0.8,"macro_precision_match":0.6267,"macro_recall_match":0.6759,"macro_f1_match":0.6423,"micro_precision_match":0.8065,"micro_recall_match":0.8065,"micro_f1_match":0.8065,"exact_matches":0.4167,"evaluatable_instances":0.5167,"rougeL":80.0}
{"task":"overall","prediction_file":"..\/inference\/predictions_cappr.jsonl","macro_precision":0.3262391304,"macro_recall":0.4802826087,"macro_f1":0.3490521739,"micro_precision":0.4802826087,"micro_recall":0.4802826087,"micro_f1":0.4802826087,"macro_precision_match":0.197773913,"macro_recall_match":0.3111478261,"macro_f1_match":0.2176478261,"micro_precision_match":0.2993347826,"micro_recall_match":0.2993347826,"micro_f1_match":0.2993347826,"exact_matches":0.2215956522,"evaluatable_instances":0.4905826087,"rougeL":68.8853217391}
{"task":"overall","prediction_file":"..\/inference\/predictions_default.jsonl","macro_precision":0.3059304348,"macro_recall":0.2626565217,"macro_f1":0.2324043478,"micro_precision":0.3695956522,"micro_recall":0.2626565217,"micro_f1":0.2881608696,"macro_precision_match":0.3059304348,"macro_recall_match":0.3302565217,"macro_f1_match":0.2734956522,"micro_precision_match":0.3695956522,"micro_recall_match":0.3695956522,"micro_f1_match":0.3695956522,"exact_matches":0.2626565217,"evaluatable_instances":0.4905826087,"rougeL":51.3240869565}
{"task":"overall","prediction_file":"..\/inference\/predictions_guidance.jsonl","macro_precision":0.3447304348,"macro_recall":0.4786695652,"macro_f1":0.3650130435,"micro_precision":0.4786695652,"micro_recall":0.4786695652,"micro_f1":0.4786695652,"macro_precision_match":0.2141608696,"macro_recall_match":0.3106652174,"macro_f1_match":0.2231913043,"micro_precision_match":0.3216043478,"micro_recall_match":0.3216043478,"micro_f1_match":0.3216043478,"exact_matches":0.2293956522,"evaluatable_instances":0.4905826087,"rougeL":69.4020826087}
{"task":"overall","prediction_file":"..\/inference\/predictions_outline.jsonl","macro_precision":0.4587652174,"macro_recall":0.5242391304,"macro_f1":0.4385695652,"micro_precision":0.5242391304,"micro_recall":0.5242391304,"micro_f1":0.5242391304,"macro_precision_match":0.3142434783,"macro_recall_match":0.3379043478,"macro_f1_match":0.2811826087,"micro_precision_match":0.3667913043,"micro_recall_match":0.3667913043,"micro_f1_match":0.3667913043,"exact_matches":0.2612086957,"evaluatable_instances":0.4905826087,"rougeL":71.8361043478}
{"task":"overall","prediction_file":"..\/inference\/predictions_random.jsonl","macro_precision":0.4665869565,"macro_recall":0.4676695652,"macro_f1":0.4651652174,"micro_precision":0.4676695652,"micro_recall":0.4676695652,"micro_f1":0.4676695652,"macro_precision_match":0.3225869565,"macro_recall_match":0.3236217391,"macro_f1_match":0.3136478261,"micro_precision_match":0.3242782609,"micro_recall_match":0.3242782609,"micro_f1_match":0.3242782609,"exact_matches":0.2375956522,"evaluatable_instances":0.4905826087,"rougeL":67.0242130435}
