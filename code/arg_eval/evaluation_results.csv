task,task_type,task_is_ca,dataset,approach,macro_f1,mase,rougeL,exact_matches
propositional-relations-identification_qt30,clf,ca,qt30,llama3-8b-instruct,0.2286410432395333,,0.52,0.31
illocutionary-relations-identification_qt30,clf,ca,qt30,llama3-8b-instruct,0.10588666990268822,,0.19801980198019803,0.18811881188118812
argument-reasoning-comprehension_argument-reasoning-comprehension,gen,ca,argument-reasoning-comprehension,llama3-8b-instruct,,,0.8214602245305654,0.0
inappropriateness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,llama3-8b-instruct,0.6129302228266555,,0.63,0.63
toxic-emotions-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,llama3-8b-instruct,0.5225694444444444,,0.8533333333333337,0.56
missing-commitment-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,llama3-8b-instruct,0.6491228070175439,,0.8833333333333337,0.65
missing-intelligibility-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,llama3-8b-instruct,0.5174632352941176,,0.8600000000000001,0.58
other-inappropriateness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,llama3-8b-instruct,0.180412905903102,,0.9281818181818167,0.21
excessive-intensity-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,llama3-8b-instruct,0.4171928120446819,,0.76,0.52
emotional-deception-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,llama3-8b-instruct,0.3333333333333333,,0.9285714285714287,0.5
missing-seriousness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,llama3-8b-instruct,0.5249681381068243,,0.8633333333333336,0.59
missing-openness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,llama3-8b-instruct,0.4456893501592169,,0.8433333333333334,0.53
unclear-meaning-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,llama3-8b-instruct,0.3333333333333333,,0.75,0.5
missing-relevance-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,llama3-8b-instruct,0.40910670837678137,,0.7814285714285708,0.49
confusing-reasoning-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,llama3-8b-instruct,0.3939393939393939,,0.825,0.65
detrimental-orthography-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,llama3-8b-instruct,0.46236559139784944,,0.93,0.86
reason-unclassified-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,llama3-8b-instruct,0.0985576923076923,,0.8199999999999984,0.1
key-point-matching_argkp,clf,ca,argkp,llama3-8b-instruct,0.5024875621890548,,0.56,0.56
key-point-generation_argkp,gen,ca,argkp,llama3-8b-instruct,,,0.22286410047710745,0.0
pragmatic-tagging_f1000rd,gen,ca,f1000rd,llama3-8b-instruct,,,0.24848100545031304,0.0
same-side-stance-classification_webis-sameside-19,clf,ca,webis-sameside-19,llama3-8b-instruct,0.49979991996798717,,0.8333333333333335,0.5
novelty-classification_argsvalidnovel,clf,ca,argsvalidnovel,llama3-8b-instruct,0.4554512802687985,,0.53,0.53
validity-classification_argsvalidnovel,clf,ca,argsvalidnovel,llama3-8b-instruct,0.69662098545873,,0.71,0.71
relative-novelty-classification_argsvalidnovel,clf,ca,argsvalidnovel,llama3-8b-instruct,0.24476190476190474,,0.3137254901960784,0.3137254901960784
relative-validity-classification_argsvalidnovel,clf,ca,argsvalidnovel,llama3-8b-instruct,0.2645856558900037,,0.3333333333333333,0.3333333333333333
identifying-argument-components_argument-annotated-essays-2,gen,ca,argument-annotated-essays-2,llama3-8b-instruct,,,0.4890947004175155,0.0
classifying-argument-components_argument-annotated-essays-2,gen,ca,argument-annotated-essays-2,llama3-8b-instruct,,,0.7045654393301443,0.0
identifying-argumentative-relations_argument-annotated-essays-2,clf,ca,argument-annotated-essays-2,llama3-8b-instruct,0.5308037535699714,,0.54,0.54
stance-recognition_argument-annotated-essays-2,clf,ca,argument-annotated-essays-2,llama3-8b-instruct,0.5463252343986289,,0.55,0.55
rate-local-acceptability_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,llama3-8b-instruct,,1.4814814814814812,0.19999999999999998,0.0
rate-local-relevance_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,llama3-8b-instruct,,1.4285714285714288,0.2333333333333333,0.0
rate-local-sufficiency_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,llama3-8b-instruct,,2.5925925925925917,0.06666666666666667,0.0
rate-cogency_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,llama3-8b-instruct,,2.1818181818181825,0.1,0.0
rate-credibility_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,llama3-8b-instruct,,8.421052631578943,0.13333333333333333,0.0
rate-emotional-appeal_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,llama3-8b-instruct,,8.947368421052646,0.1,0.0
rate-clarity_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,llama3-8b-instruct,,4.7368421052631575,0.1,0.0
rate-appropriateness_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,llama3-8b-instruct,,1.2499999999999998,0.26666666666666666,0.0
rate-arrangement_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,llama3-8b-instruct,,3.235294117647059,0.03333333333333333,0.0
rate-effectiveness_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,llama3-8b-instruct,,2.87037037037037,0.03333333333333333,0.0
rate-global-acceptability_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,llama3-8b-instruct,,1.7543859649122806,0.13333333333333333,0.0
rate-global-relevance_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,llama3-8b-instruct,,1.7543859649122806,0.13333333333333333,0.0
rate-global-sufficiency_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,llama3-8b-instruct,,3.296703296703296,0.03333333333333333,0.0
rate-reasonableness_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,llama3-8b-instruct,,2.1666666666666665,0.03333333333333333,0.0
rate-overall-quality_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,llama3-8b-instruct,,2.4166666666666665,0.03333333333333333,0.0
detect-enthymemes_enthymemes-student-essays,clf,ca,enthymemes-student-essays,llama3-8b-instruct,0.3551783129359126,,0.51,0.51
reconstruct-enthymemes_enthymemes-student-essays,gen,ca,enthymemes-student-essays,llama3-8b-instruct,,,0.13083456804538188,0.0
classifying-argument-strength_icle-argument-strength,reg,ca,icle-argument-strength,llama3-8b-instruct,,1.0612043435340572,0.53,0.0
argumentative-text-creation_microtexts,gen,ca,microtexts,llama3-8b-instruct,,,0.20713712638175025,0.0
central-claim-extraction_microtexts,gen,ca,microtexts,llama3-8b-instruct,,,0.3828506821991784,0.06060606060606061
argumentative-role-determination_microtexts,clf,ca,microtexts,llama3-8b-instruct,0.5024875621890548,,0.56,0.56
function-of-segment-determination_microtexts,clf,ca,microtexts,llama3-8b-instruct,0.12272727272727273,,0.345,0.23
unit-attachment-identification_microtexts,clf,ca,microtexts,llama3-8b-instruct,0.6347402597402598,,0.64,0.64
stance-prediction_belief-based-arguments,clf,ca,belief-based-arguments,llama3-8b-instruct,0.3005082932049224,,0.3627450980392157,0.3627450980392157
belief-based-claim-generation_belief-based-arguments,gen,ca,belief-based-arguments,llama3-8b-instruct,,,0.12771552924030355,0.0
argument-clause-recognition_echr,clf,ca,echr,llama3-8b-instruct,0.5021573182874212,,0.55,0.55
clause-relation-prediction_echr,clf,ca,echr,llama3-8b-instruct,0.39117199391172,,0.9563636363636355,0.52
premise-recognition_echr,clf,ca,echr,llama3-8b-instruct,0.3453985367731998,,0.49,0.49
conlusion-recognition_echr,clf,ca,echr,llama3-8b-instruct,0.56,,0.56,0.56
reason-identification_reason-identification-and-classification,gen,ca,reason-identification-and-classification,llama3-8b-instruct,,,0.3683927121633607,0.0
conclusion-generation_webis-conclugen-21,gen,ca,webis-conclugen-21,llama3-8b-instruct,,,0.1823240213254908,0.0
quality-assessment_ibm-rank-30k,reg,ca,ibm-rank-30k,llama3-8b-instruct,,4.929279251448091,0.5,0.0
stance-prediction_ibm-rank-30k,clf,ca,ibm-rank-30k,llama3-8b-instruct,0.5558672276764843,,0.62,0.62
extractive-summarization_debate-dum,gen,ca,debate-dum,llama3-8b-instruct,,,0.4770091490291445,0.0
review-helpfulness-prediction_amazon-review-dataset,reg,ca,amazon-review-dataset,llama3-8b-instruct,,2.5128564749883124,0.35333333333333344,0.0
unit-segmentation-prediction_amazon-review-dataset,gen,ca,amazon-review-dataset,llama3-8b-instruct,,,0.7853650544447323,0.0
unit-classification-prediction_amazon-review-dataset,gen,ca,amazon-review-dataset,llama3-8b-instruct,,,0.13653704533281977,0.0
relation-detection_amazon-review-dataset,clf,ca,amazon-review-dataset,llama3-8b-instruct,0.32962962962962966,,0.46,0.46
classify-more-convincing-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,llama3-8b-instruct,0.5555555555555556,,0.805,0.61
classify-more-details-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,llama3-8b-instruct,0.4357782940590773,,0.49,0.49
classify-more-balanced-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,llama3-8b-instruct,0.43227899432278993,,0.51,0.51
classify-more-credible-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,llama3-8b-instruct,0.4949494949494949,,0.5,0.5
classify-more-clear-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,llama3-8b-instruct,0.5899589958995899,,0.59,0.59
classify-more-on-topic-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,llama3-8b-instruct,0.4171928120446819,,0.52,0.52
classify-more-provoking-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,llama3-8b-instruct,0.3985139757046821,,0.49,0.49
classify-more-smart-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,llama3-8b-instruct,0.567882624861823,,0.57,0.57
classify-less-attacking-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,llama3-8b-instruct,0.3706597222222222,,0.42,0.42
classify-less-language-issues-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,llama3-8b-instruct,0.3197278911564626,,0.47,0.47
classify-less-unclear-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,llama3-8b-instruct,0.3743099006256901,,0.49,0.49
classify-less-facts-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,llama3-8b-instruct,0.5192307692307692,,0.52,0.52
classify-less-reasoning-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,llama3-8b-instruct,0.3288590604026846,,0.49,0.49
classify-less-relevant-reasons_ukp-convarg-2,clf,ca,ukp-convarg-2,llama3-8b-instruct,0.32432432432432434,,0.48,0.48
classify-not-an-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,llama3-8b-instruct,0.3497730339835603,,0.47,0.47
classify-nonsense-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,llama3-8b-instruct,0.40577249575551777,,0.44,0.44
classify-off-topic-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,llama3-8b-instruct,0.3503118503118503,,0.5,0.5
classify-generally-weak-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,llama3-8b-instruct,0.3497730339835603,,0.47,0.47
detect-persuasive-documents_aaugwd,clf,ca,aaugwd,llama3-8b-instruct,0.3551587301587301,,0.8266666666666669,0.48
extract-toulmin-components_aaugwd,gen,ca,aaugwd,llama3-8b-instruct,,,0.4630051100588451,0.0
stance-detection_comarg,clf,ca,comarg,llama3-8b-instruct,0.1808080808080808,,0.7780769230769228,0.3
argument-similarity_ukp-aspect-corpus,clf,ca,ukp-aspect-corpus,llama3-8b-instruct,0.2975896380168125,,0.4533333333333336,0.0
argument-identification_UKP-sentential-argument-mining,clf,ca,UKP-sentential-argument-mining,llama3-8b-instruct,0.5119258971408833,,0.7745098039215687,0.5490196078431373
same-debate-opposing-counters_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,llama3-8b-instruct,,,0.22140496225416606,0.0
same-debate-counters_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,llama3-8b-instruct,,,0.25607437816694884,0.0
same-debate-opposing-argument_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,llama3-8b-instruct,,,0.1976540979197309,0.0
same-debate-argument_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,llama3-8b-instruct,,,0.18559441580484884,0.0
predict-agreement_iac-v2,reg,ca,iac-v2,llama3-8b-instruct,,3.235408100111377,0.28,0.0
predict-respect_iac-v2,reg,ca,iac-v2,llama3-8b-instruct,,4.129932475208493,0.305,0.0
predict-factuality_iac-v2,reg,ca,iac-v2,llama3-8b-instruct,,2.741344271870422,0.32,0.0
predict-nice_iac-v2,reg,ca,iac-v2,llama3-8b-instruct,,4.0717888597125835,0.3,0.0
predict-sarcasm_iac-v2,reg,ca,iac-v2,llama3-8b-instruct,,5.267197753301976,0.41,0.0
synthesize-argument_argumentation-synthesis,gen,ca,argumentation-synthesis,llama3-8b-instruct,,,0.1699100475058867,0.0
claim-revision-improvement_claim-revision-pair-corpus,clf,ca,claim-revision-pair-corpus,llama3-8b-instruct,0.47916666666666663,,0.76,0.52
suboptimal-claim-detection_claim-revision-pair-corpus,clf,ca,claim-revision-pair-corpus,llama3-8b-instruct,0.46960424316605465,,0.48,0.48
claim-improvement-suggestions_claim-revision-pair-corpus,clf,ca,claim-revision-pair-corpus,llama3-8b-instruct,0.07467948717948718,,0.22,0.15
claim-optimization_claim-revision-pair-corpus,gen,ca,claim-revision-pair-corpus,llama3-8b-instruct,,,0.5926802711137048,0.0
aspect-controlled-argument-generation_aspect-controlled-argument-generation,gen,ca,aspect-controlled-argument-generation,llama3-8b-instruct,,,0.09676914997368048,0.0
propositional-relations-identification_qt30,clf,ca,qt30,alpaca,0.19297752808988763,,0.52,0.3
illocutionary-relations-identification_qt30,clf,ca,qt30,alpaca,0.08243098892449541,,0.19801980198019803,0.19801980198019803
argument-reasoning-comprehension_argument-reasoning-comprehension,gen,ca,argument-reasoning-comprehension,alpaca,,,0.8068250019377827,0.0
inappropriateness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,alpaca,0.508679986898133,,0.55,0.55
toxic-emotions-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,alpaca,0.5847828526540231,,0.8766666666666667,0.63
missing-commitment-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,alpaca,0.3333333333333333,,0.8333333333333335,0.5
missing-intelligibility-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,alpaca,0.3551783129359126,,0.8366666666666667,0.51
other-inappropriateness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,alpaca,0.45098039215686275,,0.9745454545454544,0.72
excessive-intensity-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,alpaca,0.3333333333333333,,0.75,0.5
emotional-deception-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,alpaca,0.39117199391172,,0.9314285714285715,0.52
missing-seriousness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,alpaca,0.3333333333333333,,0.8333333333333335,0.5
missing-openness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,alpaca,0.3333333333333333,,0.8333333333333335,0.5
unclear-meaning-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,alpaca,0.3333333333333333,,0.75,0.5
missing-relevance-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,alpaca,0.3333333333333333,,0.7857142857142853,0.5
confusing-reasoning-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,alpaca,0.3939393939393939,,0.825,0.65
detrimental-orthography-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,alpaca,0.46236559139784944,,0.93,0.86
reason-unclassified-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,alpaca,0.10776942355889725,,0.8219999999999986,0.11
key-point-matching_argkp,clf,ca,argkp,alpaca,0.529239460194581,,0.55,0.55
key-point-generation_argkp,gen,ca,argkp,alpaca,,,0.215627473457245,0.0
pragmatic-tagging_f1000rd,gen,ca,f1000rd,alpaca,,,0.084695804788628,0.0
same-side-stance-classification_webis-sameside-19,clf,ca,webis-sameside-19,alpaca,0.3894165535956581,,0.8199999999999998,0.46
novelty-classification_argsvalidnovel,clf,ca,argsvalidnovel,alpaca,0.5512035903712771,,0.56,0.56
validity-classification_argsvalidnovel,clf,ca,argsvalidnovel,alpaca,0.6043956043956044,,0.64,0.64
relative-novelty-classification_argsvalidnovel,clf,ca,argsvalidnovel,alpaca,0.28366991479546205,,0.3627450980392157,0.3627450980392157
relative-validity-classification_argsvalidnovel,clf,ca,argsvalidnovel,alpaca,0.21115593267492003,,0.2647058823529412,0.2647058823529412
identifying-argument-components_argument-annotated-essays-2,gen,ca,argument-annotated-essays-2,alpaca,,,0.30219293021284,0.0
classifying-argument-components_argument-annotated-essays-2,gen,ca,argument-annotated-essays-2,alpaca,,,0.32619123557188134,0.0
identifying-argumentative-relations_argument-annotated-essays-2,clf,ca,argument-annotated-essays-2,alpaca,0.3453985367731998,,0.49,0.49
stance-recognition_argument-annotated-essays-2,clf,ca,argument-annotated-essays-2,alpaca,0.29577464788732394,,0.42,0.42
rate-local-acceptability_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,alpaca,,0.9259259259259257,0.33333333333333337,0.0
rate-local-relevance_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,alpaca,,0.8163265306122451,0.4,0.0
rate-local-sufficiency_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,alpaca,,1.2037037037037035,0.2333333333333333,0.0
rate-cogency_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,alpaca,,1.0909090909090913,0.26666666666666666,0.0
rate-credibility_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,alpaca,,1.5789473684210518,0.5666666666666665,0.0
rate-emotional-appeal_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,alpaca,,0.5263157894736852,0.6333333333333331,0.0
rate-clarity_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,alpaca,,1.3157894736842106,0.4999999999999999,0.0
rate-appropriateness_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,alpaca,,0.769230769230769,0.4,0.0
rate-arrangement_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,alpaca,,0.7352941176470588,0.4999999999999999,0.0
rate-effectiveness_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,alpaca,,1.7592592592592586,0.16666666666666666,0.0
rate-global-acceptability_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,alpaca,,0.9649122807017544,0.3,0.0
rate-global-relevance_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,alpaca,,1.1403508771929824,0.3,0.0
rate-global-sufficiency_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,alpaca,,1.648351648351648,0.19999999999999998,0.0
rate-reasonableness_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,alpaca,,1.0833333333333333,0.2333333333333333,0.0
rate-overall-quality_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,alpaca,,1.1666666666666667,0.19999999999999998,0.0
detect-enthymemes_enthymemes-student-essays,clf,ca,enthymemes-student-essays,alpaca,0.411525974025974,,0.42,0.42
reconstruct-enthymemes_enthymemes-student-essays,gen,ca,enthymemes-student-essays,alpaca,,,0.14143770093630542,0.0
classifying-argument-strength_icle-argument-strength,reg,ca,icle-argument-strength,alpaca,,1.4807502467917077,0.525,0.0
argumentative-text-creation_microtexts,gen,ca,microtexts,alpaca,,,0.19020427726275912,0.0
central-claim-extraction_microtexts,gen,ca,microtexts,alpaca,,,0.359879490561705,0.0
argumentative-role-determination_microtexts,clf,ca,microtexts,alpaca,0.5555555555555556,,0.61,0.61
function-of-segment-determination_microtexts,clf,ca,microtexts,alpaca,0.09508196721311475,,0.35,0.29
unit-attachment-identification_microtexts,clf,ca,microtexts,alpaca,0.39673982800667434,,0.53,0.53
stance-prediction_belief-based-arguments,clf,ca,belief-based-arguments,alpaca,0.2489118477065098,,0.3333333333333333,0.3333333333333333
belief-based-claim-generation_belief-based-arguments,gen,ca,belief-based-arguments,alpaca,,,0.09864312876632672,0.0
argument-clause-recognition_echr,clf,ca,echr,alpaca,0.3333333333333333,,0.5,0.5
clause-relation-prediction_echr,clf,ca,echr,alpaca,0.3710691823899371,,0.9554545454545447,0.51
premise-recognition_echr,clf,ca,echr,alpaca,0.40476190476190477,,0.5,0.5
conlusion-recognition_echr,clf,ca,echr,alpaca,0.3288590604026846,,0.49,0.49
reason-identification_reason-identification-and-classification,gen,ca,reason-identification-and-classification,alpaca,,,0.3346285193163909,0.0
conclusion-generation_webis-conclugen-21,gen,ca,webis-conclugen-21,alpaca,,,0.1950560959044349,0.0
quality-assessment_ibm-rank-30k,reg,ca,ibm-rank-30k,alpaca,,4.929279251448091,0.5,0.0
stance-prediction_ibm-rank-30k,clf,ca,ibm-rank-30k,alpaca,0.5400400990682863,,0.61,0.61
extractive-summarization_debate-dum,gen,ca,debate-dum,alpaca,,,0.3665540121528997,0.0
review-helpfulness-prediction_amazon-review-dataset,reg,ca,amazon-review-dataset,alpaca,,2.279102384291725,0.3933333333333333,0.0
unit-segmentation-prediction_amazon-review-dataset,gen,ca,amazon-review-dataset,alpaca,,,0.7196131776131952,0.0
unit-classification-prediction_amazon-review-dataset,gen,ca,amazon-review-dataset,alpaca,,,0.07266844969070978,0.0
relation-detection_amazon-review-dataset,clf,ca,amazon-review-dataset,alpaca,0.19638242894056848,,0.38,0.38
classify-more-convincing-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,alpaca,0.5863970588235294,,0.82,0.64
classify-more-details-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,alpaca,0.38557993730407525,,0.51,0.51
classify-more-balanced-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,alpaca,0.5280995280995281,,0.56,0.56
classify-more-credible-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,alpaca,0.46236559139784944,,0.54,0.54
classify-more-clear-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,alpaca,0.43899018232819076,,0.52,0.52
classify-more-on-topic-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,alpaca,0.40476190476190477,,0.5,0.5
classify-more-provoking-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,alpaca,0.4285714285714286,,0.52,0.52
classify-more-smart-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,alpaca,0.5305164319248826,,0.57,0.57
classify-less-attacking-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,alpaca,0.37704571850913315,,0.41,0.41
classify-less-language-issues-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,alpaca,0.3894165535956581,,0.46,0.46
classify-less-unclear-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,alpaca,0.3333333333333333,,0.5,0.5
classify-less-facts-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,alpaca,0.3551783129359126,,0.51,0.51
classify-less-reasoning-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,alpaca,0.46374946374946374,,0.5,0.5
classify-less-relevant-reasons_ukp-convarg-2,clf,ca,ukp-convarg-2,alpaca,0.36680235187697874,,0.44,0.44
classify-not-an-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,alpaca,0.3288590604026846,,0.49,0.49
classify-nonsense-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,alpaca,0.3333333333333333,,0.5,0.5
classify-off-topic-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,alpaca,0.40910670837678137,,0.49,0.49
classify-generally-weak-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,alpaca,0.3503118503118503,,0.5,0.5
detect-persuasive-documents_aaugwd,clf,ca,aaugwd,alpaca,0.38557993730407525,,0.8366666666666669,0.51
extract-toulmin-components_aaugwd,gen,ca,aaugwd,alpaca,,,0.3710008064224655,0.0
stance-detection_comarg,clf,ca,comarg,alpaca,0.08561127499180596,,0.7610805860805857,0.21
argument-similarity_ukp-aspect-corpus,clf,ca,ukp-aspect-corpus,alpaca,0.22195383789586687,,0.47000000000000014,0.0
argument-identification_UKP-sentential-argument-mining,clf,ca,UKP-sentential-argument-mining,alpaca,0.2884206045125585,,0.7009803921568627,0.4019607843137255
same-debate-opposing-counters_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,alpaca,,,0.2843230179903349,0.0
same-debate-counters_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,alpaca,,,0.1625190079913983,0.0
same-debate-opposing-argument_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,alpaca,,,0.12273001151277668,0.0
same-debate-argument_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,alpaca,,,0.046914740676010605,0.0
predict-agreement_iac-v2,reg,ca,iac-v2,alpaca,,3.1947074686772017,0.265,0.0
predict-respect_iac-v2,reg,ca,iac-v2,alpaca,,3.7217920379388527,0.315,0.0
predict-factuality_iac-v2,reg,ca,iac-v2,alpaca,,3.1639017600901322,0.33,0.0
predict-nice_iac-v2,reg,ca,iac-v2,alpaca,,3.851609725491543,0.29,0.0
predict-sarcasm_iac-v2,reg,ca,iac-v2,alpaca,,0.9731116301486148,0.405,0.0
synthesize-argument_argumentation-synthesis,gen,ca,argumentation-synthesis,alpaca,,,0.17854218365245628,0.0
claim-revision-improvement_claim-revision-pair-corpus,clf,ca,claim-revision-pair-corpus,alpaca,0.47482236638863146,,0.745,0.49
suboptimal-claim-detection_claim-revision-pair-corpus,clf,ca,claim-revision-pair-corpus,alpaca,0.3894165535956581,,0.46,0.46
claim-improvement-suggestions_claim-revision-pair-corpus,clf,ca,claim-revision-pair-corpus,alpaca,0.15932888816609747,,0.275,0.19
claim-optimization_claim-revision-pair-corpus,gen,ca,claim-revision-pair-corpus,alpaca,,,0.47594403217437764,0.0
aspect-controlled-argument-generation_aspect-controlled-argument-generation,gen,ca,aspect-controlled-argument-generation,alpaca,,,0.10320574344446029,0.0
propositional-relations-identification_qt30,clf,ca,qt30,gemma-2-9b-it,0.37875955466932537,,0.57,0.44
illocutionary-relations-identification_qt30,clf,ca,qt30,gemma-2-9b-it,0.10688228335287157,,0.24092409240924095,0.21782178217821782
argument-reasoning-comprehension_argument-reasoning-comprehension,gen,ca,argument-reasoning-comprehension,gemma-2-9b-it,,,0.5979836296887036,0.0
inappropriateness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,gemma-2-9b-it,0.3333333333333333,,0.5,0.5
toxic-emotions-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,gemma-2-9b-it,0.6816638370118846,,0.9000000000000001,0.7
missing-commitment-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,gemma-2-9b-it,0.6656239887822242,,0.8966666666666668,0.69
missing-intelligibility-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,gemma-2-9b-it,0.5894909688013137,,0.8666666666666668,0.6
other-inappropriateness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,gemma-2-9b-it,0.4858352656517794,,0.9536363636363626,0.49
excessive-intensity-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,gemma-2-9b-it,0.5400400990682863,,0.805,0.61
emotional-deception-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,gemma-2-9b-it,0.4295634920634921,,0.9342857142857145,0.54
missing-seriousness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,gemma-2-9b-it,0.5174632352941176,,0.8600000000000003,0.58
missing-openness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,gemma-2-9b-it,0.483110950835437,,0.8566666666666669,0.57
unclear-meaning-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,gemma-2-9b-it,0.3333333333333333,,0.75,0.5
missing-relevance-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,gemma-2-9b-it,0.6897207486738064,,0.8671428571428568,0.69
confusing-reasoning-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,gemma-2-9b-it,0.3939393939393939,,0.825,0.65
detrimental-orthography-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,gemma-2-9b-it,0.46236559139784944,,0.93,0.86
reason-unclassified-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,gemma-2-9b-it,0.06542056074766354,,0.8139999999999985,0.07
key-point-matching_argkp,clf,ca,argkp,gemma-2-9b-it,0.8095238095238095,,0.81,0.81
key-point-generation_argkp,gen,ca,argkp,gemma-2-9b-it,,,0.19400293306890784,0.0
pragmatic-tagging_f1000rd,gen,ca,f1000rd,gemma-2-9b-it,,,0.026645464808719432,0.0
same-side-stance-classification_webis-sameside-19,clf,ca,webis-sameside-19,gemma-2-9b-it,0.3453985367731998,,0.8300000000000002,0.49
novelty-classification_argsvalidnovel,clf,ca,argsvalidnovel,gemma-2-9b-it,0.49269480519480524,,0.5,0.5
validity-classification_argsvalidnovel,clf,ca,argsvalidnovel,gemma-2-9b-it,0.7398959583833533,,0.74,0.74
relative-novelty-classification_argsvalidnovel,clf,ca,argsvalidnovel,gemma-2-9b-it,0.22381573229030857,,0.3137254901960784,0.3137254901960784
relative-validity-classification_argsvalidnovel,clf,ca,argsvalidnovel,gemma-2-9b-it,0.197895002205836,,0.3333333333333333,0.3333333333333333
identifying-argument-components_argument-annotated-essays-2,gen,ca,argument-annotated-essays-2,gemma-2-9b-it,,,0.5445311508118083,0.0
classifying-argument-components_argument-annotated-essays-2,gen,ca,argument-annotated-essays-2,gemma-2-9b-it,,,0.6822055332896377,0.0
identifying-argumentative-relations_argument-annotated-essays-2,clf,ca,argument-annotated-essays-2,gemma-2-9b-it,0.5066495066495067,,0.54,0.54
stance-recognition_argument-annotated-essays-2,clf,ca,argument-annotated-essays-2,gemma-2-9b-it,0.719551282051282,,0.72,0.72
rate-local-acceptability_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,gemma-2-9b-it,,2.0370370370370368,0.13333333333333333,0.0
rate-local-relevance_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,gemma-2-9b-it,,2.0408163265306127,0.13333333333333333,0.0
rate-local-sufficiency_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,gemma-2-9b-it,,0.9259259259259257,0.33333333333333337,0.0
rate-cogency_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,gemma-2-9b-it,,1.0000000000000004,0.3,0.0
rate-credibility_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,gemma-2-9b-it,,4.210526315789472,0.4,0.0
rate-emotional-appeal_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,gemma-2-9b-it,,6.315789473684221,0.26666666666666666,0.0
rate-clarity_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,gemma-2-9b-it,,2.6315789473684212,0.33333333333333337,0.0
rate-appropriateness_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,gemma-2-9b-it,,1.4423076923076918,0.19999999999999998,0.0
rate-arrangement_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,gemma-2-9b-it,,1.3235294117647058,0.3666666666666667,0.0
rate-effectiveness_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,gemma-2-9b-it,,1.0185185185185184,0.33333333333333337,0.0
rate-global-acceptability_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,gemma-2-9b-it,,1.0526315789473684,0.26666666666666666,0.0
rate-global-relevance_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,gemma-2-9b-it,,1.0526315789473684,0.26666666666666666,0.0
rate-global-sufficiency_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,gemma-2-9b-it,,0.879120879120879,0.4,0.0
rate-reasonableness_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,gemma-2-9b-it,,0.9166666666666666,0.3,0.0
rate-overall-quality_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,gemma-2-9b-it,,0.9166666666666667,0.3,0.0
detect-enthymemes_enthymemes-student-essays,clf,ca,enthymemes-student-essays,gemma-2-9b-it,0.3333333333333333,,0.5,0.5
reconstruct-enthymemes_enthymemes-student-essays,gen,ca,enthymemes-student-essays,gemma-2-9b-it,,,0.11474864016831406,0.0
classifying-argument-strength_icle-argument-strength,reg,ca,icle-argument-strength,gemma-2-9b-it,,1.7028627838104637,0.525,0.0
argumentative-text-creation_microtexts,gen,ca,microtexts,gemma-2-9b-it,,,0.16729020640728245,0.0
central-claim-extraction_microtexts,gen,ca,microtexts,gemma-2-9b-it,,,0.46871948137668257,0.0
argumentative-role-determination_microtexts,clf,ca,microtexts,gemma-2-9b-it,0.5733333333333333,,0.68,0.68
function-of-segment-determination_microtexts,clf,ca,microtexts,gemma-2-9b-it,0.22917293233082706,,0.5,0.45
unit-attachment-identification_microtexts,clf,ca,microtexts,gemma-2-9b-it,0.6828644501278772,,0.69,0.69
stance-prediction_belief-based-arguments,clf,ca,belief-based-arguments,gemma-2-9b-it,0.2515005123700776,,0.3235294117647059,0.3235294117647059
belief-based-claim-generation_belief-based-arguments,gen,ca,belief-based-arguments,gemma-2-9b-it,,,0.12406258599217629,0.0
argument-clause-recognition_echr,clf,ca,echr,gemma-2-9b-it,0.39673982800667434,,0.53,0.53
clause-relation-prediction_echr,clf,ca,echr,gemma-2-9b-it,0.3333333333333333,,0.9545454545454538,0.5
premise-recognition_echr,clf,ca,echr,gemma-2-9b-it,0.3503118503118503,,0.5,0.5
conlusion-recognition_echr,clf,ca,echr,gemma-2-9b-it,0.4724573671942093,,0.57,0.57
reason-identification_reason-identification-and-classification,gen,ca,reason-identification-and-classification,gemma-2-9b-it,,,0.2183283853793129,0.0
conclusion-generation_webis-conclugen-21,gen,ca,webis-conclugen-21,gemma-2-9b-it,,,0.153347557543602,0.0
quality-assessment_ibm-rank-30k,reg,ca,ibm-rank-30k,gemma-2-9b-it,,4.929279251448091,0.5,0.0
stance-prediction_ibm-rank-30k,clf,ca,ibm-rank-30k,gemma-2-9b-it,0.7564935064935066,,0.76,0.76
extractive-summarization_debate-dum,gen,ca,debate-dum,gemma-2-9b-it,,,0.5783824611791206,0.0
review-helpfulness-prediction_amazon-review-dataset,reg,ca,amazon-review-dataset,gemma-2-9b-it,,2.536231884057971,0.35333333333333344,0.0
unit-segmentation-prediction_amazon-review-dataset,gen,ca,amazon-review-dataset,gemma-2-9b-it,,,0.554201716036851,0.0
unit-classification-prediction_amazon-review-dataset,gen,ca,amazon-review-dataset,gemma-2-9b-it,,,0.042349884134269634,0.0
relation-detection_amazon-review-dataset,clf,ca,amazon-review-dataset,gemma-2-9b-it,0.287677114641477,,0.49,0.49
classify-more-convincing-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,gemma-2-9b-it,0.6368917937545389,,0.825,0.65
classify-more-details-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,gemma-2-9b-it,0.5280995280995281,,0.56,0.56
classify-more-balanced-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,gemma-2-9b-it,0.46952257031328193,,0.47,0.47
classify-more-credible-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,gemma-2-9b-it,0.3629041952157711,,0.47,0.47
classify-more-clear-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,gemma-2-9b-it,0.48684354187138335,,0.53,0.53
classify-more-on-topic-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,gemma-2-9b-it,0.5160127690248172,,0.53,0.53
classify-more-provoking-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,gemma-2-9b-it,0.3333333333333333,,0.5,0.5
classify-more-smart-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,gemma-2-9b-it,0.3333333333333333,,0.5,0.5
classify-less-attacking-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,gemma-2-9b-it,0.3333333333333333,,0.5,0.5
classify-less-language-issues-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,gemma-2-9b-it,0.3333333333333333,,0.5,0.5
classify-less-unclear-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,gemma-2-9b-it,0.3333333333333333,,0.5,0.5
classify-less-facts-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,gemma-2-9b-it,0.3333333333333333,,0.5,0.5
classify-less-reasoning-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,gemma-2-9b-it,0.3333333333333333,,0.5,0.5
classify-less-relevant-reasons_ukp-convarg-2,clf,ca,ukp-convarg-2,gemma-2-9b-it,0.3333333333333333,,0.5,0.5
classify-not-an-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,gemma-2-9b-it,0.3333333333333333,,0.5,0.5
classify-nonsense-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,gemma-2-9b-it,0.3333333333333333,,0.5,0.5
classify-off-topic-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,gemma-2-9b-it,0.3333333333333333,,0.5,0.5
classify-generally-weak-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,gemma-2-9b-it,0.3333333333333333,,0.5,0.5
detect-persuasive-documents_aaugwd,clf,ca,aaugwd,gemma-2-9b-it,0.5477159656264134,,0.8666666666666667,0.6
extract-toulmin-components_aaugwd,gen,ca,aaugwd,gemma-2-9b-it,,,0.3118414664332077,0.0
stance-detection_comarg,clf,ca,comarg,gemma-2-9b-it,0.3283730158730159,,0.8082783882783882,0.38
argument-similarity_ukp-aspect-corpus,clf,ca,ukp-aspect-corpus,gemma-2-9b-it,0.3772218282495041,,0.5533333333333337,0.0
argument-identification_UKP-sentential-argument-mining,clf,ca,UKP-sentential-argument-mining,gemma-2-9b-it,0.4917361370328896,,0.7892156862745098,0.5784313725490197
same-debate-opposing-counters_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,gemma-2-9b-it,,,0.16606278633101249,0.0
same-debate-counters_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,gemma-2-9b-it,,,0.15494046176050993,0.0
same-debate-opposing-argument_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,gemma-2-9b-it,,,0.15131439093246804,0.0
same-debate-argument_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,gemma-2-9b-it,,,0.16950358598471052,0.0
predict-agreement_iac-v2,reg,ca,iac-v2,gemma-2-9b-it,,2.023093964165687,0.275,0.0
predict-respect_iac-v2,reg,ca,iac-v2,gemma-2-9b-it,,2.8436680811053403,0.32,0.0
predict-factuality_iac-v2,reg,ca,iac-v2,gemma-2-9b-it,,2.5035325416814325,0.35,0.0
predict-nice_iac-v2,reg,ca,iac-v2,gemma-2-9b-it,,2.8279251926974034,0.325,0.0
predict-sarcasm_iac-v2,reg,ca,iac-v2,gemma-2-9b-it,,0.9305134249475763,0.415,0.0
synthesize-argument_argumentation-synthesis,gen,ca,argumentation-synthesis,gemma-2-9b-it,,,0.1428107253088571,0.0
claim-revision-improvement_claim-revision-pair-corpus,clf,ca,claim-revision-pair-corpus,gemma-2-9b-it,0.4294865378840957,,0.715,0.43
suboptimal-claim-detection_claim-revision-pair-corpus,clf,ca,claim-revision-pair-corpus,gemma-2-9b-it,0.36580416032470825,,0.5,0.5
claim-improvement-suggestions_claim-revision-pair-corpus,clf,ca,claim-revision-pair-corpus,gemma-2-9b-it,0.16062937062937063,,0.3025,0.21
claim-optimization_claim-revision-pair-corpus,gen,ca,claim-revision-pair-corpus,gemma-2-9b-it,,,0.2588371210018217,0.0
aspect-controlled-argument-generation_aspect-controlled-argument-generation,gen,ca,aspect-controlled-argument-generation,gemma-2-9b-it,,,0.0956708597377281,0.0
propositional-relations-identification_qt30,clf,ca,qt30,Meta-Llama-3-8B-Instruct,0.1539252170831118,,0.325,0.27
illocutionary-relations-identification_qt30,clf,ca,qt30,Meta-Llama-3-8B-Instruct,0.05121167492301513,,0.3217821782178218,0.1485148514851485
argument-reasoning-comprehension_argument-reasoning-comprehension,gen,ca,argument-reasoning-comprehension,Meta-Llama-3-8B-Instruct,,,0.5777593376715994,0.0
inappropriateness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Meta-Llama-3-8B-Instruct,0.3333333333333333,,0.5,0.5
toxic-emotions-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Meta-Llama-3-8B-Instruct,0.49286472461375164,,0.856666666666667,0.57
missing-commitment-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Meta-Llama-3-8B-Instruct,0.39673982800667434,,0.8433333333333334,0.53
missing-intelligibility-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Meta-Llama-3-8B-Instruct,0.568536342515765,,0.8700000000000001,0.61
other-inappropriateness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Meta-Llama-3-8B-Instruct,0.17355371900826447,,0.9281818181818167,0.21
excessive-intensity-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Meta-Llama-3-8B-Instruct,0.45725915875169604,,0.76,0.52
emotional-deception-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Meta-Llama-3-8B-Instruct,0.3333333333333333,,0.9285714285714287,0.5
missing-seriousness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Meta-Llama-3-8B-Instruct,0.525101763907734,,0.8600000000000001,0.58
missing-openness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Meta-Llama-3-8B-Instruct,0.48717948717948717,,0.8500000000000003,0.55
unclear-meaning-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Meta-Llama-3-8B-Instruct,0.5071523019593701,,0.795,0.59
missing-relevance-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Meta-Llama-3-8B-Instruct,0.4165398274987316,,0.8028571428571424,0.54
confusing-reasoning-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Meta-Llama-3-8B-Instruct,0.5479204339963833,,0.85,0.7
detrimental-orthography-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Meta-Llama-3-8B-Instruct,0.646415943426551,,0.945,0.89
reason-unclassified-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Meta-Llama-3-8B-Instruct,0.06542056074766354,,0.8139999999999985,0.07
key-point-matching_argkp,clf,ca,argkp,Meta-Llama-3-8B-Instruct,0.7767857142857143,,0.78,0.78
key-point-generation_argkp,gen,ca,argkp,Meta-Llama-3-8B-Instruct,,,0.18352060509700951,0.0
pragmatic-tagging_f1000rd,gen,ca,f1000rd,Meta-Llama-3-8B-Instruct,,,0.041893391348782984,0.0
same-side-stance-classification_webis-sameside-19,clf,ca,webis-sameside-19,Meta-Llama-3-8B-Instruct,0.3551783129359126,,0.8366666666666669,0.51
novelty-classification_argsvalidnovel,clf,ca,argsvalidnovel,Meta-Llama-3-8B-Instruct,0.3894165535956581,,0.46,0.46
validity-classification_argsvalidnovel,clf,ca,argsvalidnovel,Meta-Llama-3-8B-Instruct,0.7390606182256123,,0.74,0.74
relative-novelty-classification_argsvalidnovel,clf,ca,argsvalidnovel,Meta-Llama-3-8B-Instruct,0.18269762299613046,,0.3333333333333333,0.3333333333333333
relative-validity-classification_argsvalidnovel,clf,ca,argsvalidnovel,Meta-Llama-3-8B-Instruct,0.16666666666666666,,0.3333333333333333,0.3333333333333333
identifying-argument-components_argument-annotated-essays-2,gen,ca,argument-annotated-essays-2,Meta-Llama-3-8B-Instruct,,,0.3996946410186437,0.0
classifying-argument-components_argument-annotated-essays-2,gen,ca,argument-annotated-essays-2,Meta-Llama-3-8B-Instruct,,,0.6794704174387144,0.0
identifying-argumentative-relations_argument-annotated-essays-2,clf,ca,argument-annotated-essays-2,Meta-Llama-3-8B-Instruct,0.5021573182874212,,0.55,0.55
stance-recognition_argument-annotated-essays-2,clf,ca,argument-annotated-essays-2,Meta-Llama-3-8B-Instruct,0.29577464788732394,,0.42,0.42
rate-local-acceptability_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Meta-Llama-3-8B-Instruct,,2.0370370370370368,0.13333333333333333,0.0
rate-local-relevance_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Meta-Llama-3-8B-Instruct,,2.6530612244897966,0.03333333333333333,0.0
rate-local-sufficiency_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Meta-Llama-3-8B-Instruct,,0.8333333333333331,0.4,0.0
rate-cogency_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Meta-Llama-3-8B-Instruct,,1.0000000000000004,0.33333333333333337,0.0
rate-credibility_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Meta-Llama-3-8B-Instruct,,9.999999999999995,0.03333333333333333,0.0
rate-emotional-appeal_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Meta-Llama-3-8B-Instruct,,10.000000000000018,0.03333333333333333,0.0
rate-clarity_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Meta-Llama-3-8B-Instruct,,5.0,0.06666666666666667,0.0
rate-appropriateness_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Meta-Llama-3-8B-Instruct,,2.596153846153846,0.03333333333333333,0.0
rate-arrangement_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Meta-Llama-3-8B-Instruct,,2.4999999999999996,0.13333333333333333,0.0
rate-effectiveness_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Meta-Llama-3-8B-Instruct,,0.8333333333333331,0.4,0.0
rate-global-acceptability_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Meta-Llama-3-8B-Instruct,,1.6666666666666663,0.19999999999999998,0.0
rate-global-relevance_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Meta-Llama-3-8B-Instruct,,2.0175438596491224,0.13333333333333333,0.0
rate-global-sufficiency_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Meta-Llama-3-8B-Instruct,,0.769230769230769,0.4333333333333333,0.0
rate-reasonableness_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Meta-Llama-3-8B-Instruct,,0.9999999999999998,0.33333333333333337,0.0
rate-overall-quality_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Meta-Llama-3-8B-Instruct,,1.6666666666666667,0.19999999999999998,0.0
detect-enthymemes_enthymemes-student-essays,clf,ca,enthymemes-student-essays,Meta-Llama-3-8B-Instruct,0.3333333333333333,,0.5,0.5
reconstruct-enthymemes_enthymemes-student-essays,gen,ca,enthymemes-student-essays,Meta-Llama-3-8B-Instruct,,,0.129089287603431,0.0
classifying-argument-strength_icle-argument-strength,reg,ca,icle-argument-strength,Meta-Llama-3-8B-Instruct,,4.294175715695952,0.3,0.0
argumentative-text-creation_microtexts,gen,ca,microtexts,Meta-Llama-3-8B-Instruct,,,0.17761375447476016,0.0
central-claim-extraction_microtexts,gen,ca,microtexts,Meta-Llama-3-8B-Instruct,,,0.42930700235002867,0.0
argumentative-role-determination_microtexts,clf,ca,microtexts,Meta-Llama-3-8B-Instruct,0.6923076923076923,,0.73,0.73
function-of-segment-determination_microtexts,clf,ca,microtexts,Meta-Llama-3-8B-Instruct,0.05217391304347826,,0.15,0.15
unit-attachment-identification_microtexts,clf,ca,microtexts,Meta-Llama-3-8B-Instruct,0.6124031007751938,,0.62,0.62
stance-prediction_belief-based-arguments,clf,ca,belief-based-arguments,Meta-Llama-3-8B-Instruct,0.25707547169811323,,0.3235294117647059,0.3235294117647059
belief-based-claim-generation_belief-based-arguments,gen,ca,belief-based-arguments,Meta-Llama-3-8B-Instruct,,,0.13551572374538054,0.0
argument-clause-recognition_echr,clf,ca,echr,Meta-Llama-3-8B-Instruct,0.3551783129359126,,0.51,0.51
clause-relation-prediction_echr,clf,ca,echr,Meta-Llama-3-8B-Instruct,0.3333333333333333,,0.9545454545454538,0.5
premise-recognition_echr,clf,ca,echr,Meta-Llama-3-8B-Instruct,0.4574652777777778,,0.5,0.5
conlusion-recognition_echr,clf,ca,echr,Meta-Llama-3-8B-Instruct,0.3710691823899371,,0.51,0.51
reason-identification_reason-identification-and-classification,gen,ca,reason-identification-and-classification,Meta-Llama-3-8B-Instruct,,,0.22117374039748067,0.0
conclusion-generation_webis-conclugen-21,gen,ca,webis-conclugen-21,Meta-Llama-3-8B-Instruct,,,0.18086162156355787,0.0
quality-assessment_ibm-rank-30k,reg,ca,ibm-rank-30k,Meta-Llama-3-8B-Instruct,,4.929279251448091,0.5,0.0
stance-prediction_ibm-rank-30k,clf,ca,ibm-rank-30k,Meta-Llama-3-8B-Instruct,0.48686371100164205,,0.5,0.5
extractive-summarization_debate-dum,gen,ca,debate-dum,Meta-Llama-3-8B-Instruct,,,0.45395104305315326,0.0
review-helpfulness-prediction_amazon-review-dataset,reg,ca,amazon-review-dataset,Meta-Llama-3-8B-Instruct,,3.5179990649836372,0.3333333333333335,0.0
unit-segmentation-prediction_amazon-review-dataset,gen,ca,amazon-review-dataset,Meta-Llama-3-8B-Instruct,,,0.43942717321400265,0.0
unit-classification-prediction_amazon-review-dataset,gen,ca,amazon-review-dataset,Meta-Llama-3-8B-Instruct,,,0.05752341758649384,0.0
relation-detection_amazon-review-dataset,clf,ca,amazon-review-dataset,Meta-Llama-3-8B-Instruct,0.07142857142857142,,0.12,0.12
classify-more-convincing-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Meta-Llama-3-8B-Instruct,0.6601791782514674,,0.835,0.67
classify-more-details-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Meta-Llama-3-8B-Instruct,0.3333333333333333,,0.5,0.5
classify-more-balanced-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Meta-Llama-3-8B-Instruct,0.3710691823899371,,0.51,0.51
classify-more-credible-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Meta-Llama-3-8B-Instruct,0.3333333333333333,,0.5,0.5
classify-more-clear-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Meta-Llama-3-8B-Instruct,0.3503118503118503,,0.5,0.5
classify-more-on-topic-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Meta-Llama-3-8B-Instruct,0.3629041952157711,,0.47,0.47
classify-more-provoking-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Meta-Llama-3-8B-Instruct,0.4233836339099497,,0.53,0.53
classify-more-smart-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Meta-Llama-3-8B-Instruct,0.3333333333333333,,0.5,0.5
classify-less-attacking-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Meta-Llama-3-8B-Instruct,0.5538956323270048,,0.57,0.57
classify-less-language-issues-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Meta-Llama-3-8B-Instruct,0.5920075321686369,,0.61,0.61
classify-less-unclear-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Meta-Llama-3-8B-Instruct,0.46647138822052514,,0.49,0.49
classify-less-facts-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Meta-Llama-3-8B-Instruct,0.3551783129359126,,0.51,0.51
classify-less-reasoning-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Meta-Llama-3-8B-Instruct,0.3551587301587301,,0.48,0.48
classify-less-relevant-reasons_ukp-convarg-2,clf,ca,ukp-convarg-2,Meta-Llama-3-8B-Instruct,0.3497730339835603,,0.47,0.47
classify-not-an-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Meta-Llama-3-8B-Instruct,0.4350282485875706,,0.53,0.53
classify-nonsense-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Meta-Llama-3-8B-Instruct,0.5396419437340154,,0.55,0.55
classify-off-topic-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Meta-Llama-3-8B-Instruct,0.5501621508525996,,0.57,0.57
classify-generally-weak-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Meta-Llama-3-8B-Instruct,0.34043632673769664,,0.48,0.48
detect-persuasive-documents_aaugwd,clf,ca,aaugwd,Meta-Llama-3-8B-Instruct,0.6347402597402598,,0.8800000000000001,0.64
extract-toulmin-components_aaugwd,gen,ca,aaugwd,Meta-Llama-3-8B-Instruct,,,0.36803352425042835,0.0
stance-detection_comarg,clf,ca,comarg,Meta-Llama-3-8B-Instruct,0.1637199720413494,,0.7801538461538456,0.25
argument-similarity_ukp-aspect-corpus,clf,ca,ukp-aspect-corpus,Meta-Llama-3-8B-Instruct,0.3362421664447836,,0.5933333333333337,0.0
argument-identification_UKP-sentential-argument-mining,clf,ca,UKP-sentential-argument-mining,Meta-Llama-3-8B-Instruct,0.4633553192444026,,0.7598039215686274,0.5196078431372549
same-debate-opposing-counters_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,Meta-Llama-3-8B-Instruct,,,0.2195793907305663,0.0
same-debate-counters_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,Meta-Llama-3-8B-Instruct,,,0.24493308557164442,0.0
same-debate-opposing-argument_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,Meta-Llama-3-8B-Instruct,,,0.19327148617800335,0.0
same-debate-argument_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,Meta-Llama-3-8B-Instruct,,,0.17651931292238807,0.0
predict-agreement_iac-v2,reg,ca,iac-v2,Meta-Llama-3-8B-Instruct,,1.408579608474551,0.305,0.0
predict-respect_iac-v2,reg,ca,iac-v2,Meta-Llama-3-8B-Instruct,,1.5722107717524387,0.435,0.0
predict-factuality_iac-v2,reg,ca,iac-v2,Meta-Llama-3-8B-Instruct,,1.1598267877225794,0.425,0.0
predict-nice_iac-v2,reg,ca,iac-v2,Meta-Llama-3-8B-Instruct,,2.5906599442851204,0.42,0.0
predict-sarcasm_iac-v2,reg,ca,iac-v2,Meta-Llama-3-8B-Instruct,,0.925925925925926,0.675,0.0
synthesize-argument_argumentation-synthesis,gen,ca,argumentation-synthesis,Meta-Llama-3-8B-Instruct,,,0.1635094675304915,0.0
claim-revision-improvement_claim-revision-pair-corpus,clf,ca,claim-revision-pair-corpus,Meta-Llama-3-8B-Instruct,0.3551783129359126,,0.755,0.51
suboptimal-claim-detection_claim-revision-pair-corpus,clf,ca,claim-revision-pair-corpus,Meta-Llama-3-8B-Instruct,0.3288590604026846,,0.49,0.49
claim-improvement-suggestions_claim-revision-pair-corpus,clf,ca,claim-revision-pair-corpus,Meta-Llama-3-8B-Instruct,0.07665094339622641,,0.28,0.18
claim-optimization_claim-revision-pair-corpus,gen,ca,claim-revision-pair-corpus,Meta-Llama-3-8B-Instruct,,,0.21463437523445464,0.0
aspect-controlled-argument-generation_aspect-controlled-argument-generation,gen,ca,aspect-controlled-argument-generation,Meta-Llama-3-8B-Instruct,,,0.10145365956892961,0.0
propositional-relations-identification_qt30,clf,ca,qt30,Mistral-7B-Instruct-v0.3,0.2893913995608911,,0.55,0.35
illocutionary-relations-identification_qt30,clf,ca,qt30,Mistral-7B-Instruct-v0.3,0.17177697224764002,,0.22937293729372935,0.1782178217821782
argument-reasoning-comprehension_argument-reasoning-comprehension,gen,ca,argument-reasoning-comprehension,Mistral-7B-Instruct-v0.3,,,0.6924577530229044,0.0
inappropriateness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Mistral-7B-Instruct-v0.3,0.6392190152801358,,0.66,0.66
toxic-emotions-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Mistral-7B-Instruct-v0.3,0.6892230576441103,,0.8966666666666667,0.69
missing-commitment-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Mistral-7B-Instruct-v0.3,0.5249681381068243,,0.8633333333333336,0.59
missing-intelligibility-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Mistral-7B-Instruct-v0.3,0.5366079703429101,,0.8500000000000001,0.55
other-inappropriateness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Mistral-7B-Instruct-v0.3,0.592074592074592,,0.9745454545454542,0.72
excessive-intensity-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Mistral-7B-Instruct-v0.3,0.3333333333333333,,0.75,0.5
emotional-deception-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Mistral-7B-Instruct-v0.3,0.48574100046750823,,0.9371428571428573,0.56
missing-seriousness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Mistral-7B-Instruct-v0.3,0.6328029375764994,,0.8800000000000006,0.64
missing-openness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Mistral-7B-Instruct-v0.3,0.6072757337742869,,0.8733333333333335,0.62
unclear-meaning-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Mistral-7B-Instruct-v0.3,0.3333333333333333,,0.75,0.5
missing-relevance-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Mistral-7B-Instruct-v0.3,0.5320855614973261,,0.8199999999999996,0.58
confusing-reasoning-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Mistral-7B-Instruct-v0.3,0.3939393939393939,,0.825,0.65
detrimental-orthography-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Mistral-7B-Instruct-v0.3,0.46236559139784944,,0.93,0.86
reason-unclassified-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,Mistral-7B-Instruct-v0.3,0.10919827845060553,,0.8219999999999985,0.11
key-point-matching_argkp,clf,ca,argkp,Mistral-7B-Instruct-v0.3,0.6756982948007113,,0.69,0.69
key-point-generation_argkp,gen,ca,argkp,Mistral-7B-Instruct-v0.3,,,0.17335309847963495,0.0
pragmatic-tagging_f1000rd,gen,ca,f1000rd,Mistral-7B-Instruct-v0.3,,,0.056373274414632496,0.0
same-side-stance-classification_webis-sameside-19,clf,ca,webis-sameside-19,Mistral-7B-Instruct-v0.3,0.6090225563909775,,0.8700000000000001,0.61
novelty-classification_argsvalidnovel,clf,ca,argsvalidnovel,Mistral-7B-Instruct-v0.3,0.38095238095238093,,0.48,0.48
validity-classification_argsvalidnovel,clf,ca,argsvalidnovel,Mistral-7B-Instruct-v0.3,0.7057587221521648,,0.72,0.72
relative-novelty-classification_argsvalidnovel,clf,ca,argsvalidnovel,Mistral-7B-Instruct-v0.3,0.19496296296296298,,0.3235294117647059,0.3235294117647059
relative-validity-classification_argsvalidnovel,clf,ca,argsvalidnovel,Mistral-7B-Instruct-v0.3,0.16296296296296295,,0.3235294117647059,0.3235294117647059
identifying-argument-components_argument-annotated-essays-2,gen,ca,argument-annotated-essays-2,Mistral-7B-Instruct-v0.3,,,0.4747206188481362,0.0
classifying-argument-components_argument-annotated-essays-2,gen,ca,argument-annotated-essays-2,Mistral-7B-Instruct-v0.3,,,0.6837973717342559,0.0
identifying-argumentative-relations_argument-annotated-essays-2,clf,ca,argument-annotated-essays-2,Mistral-7B-Instruct-v0.3,0.5361881134721174,,0.57,0.57
stance-recognition_argument-annotated-essays-2,clf,ca,argument-annotated-essays-2,Mistral-7B-Instruct-v0.3,0.72997299729973,,0.73,0.73
rate-local-acceptability_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Mistral-7B-Instruct-v0.3,,2.0370370370370368,0.13333333333333333,0.0
rate-local-relevance_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Mistral-7B-Instruct-v0.3,,2.8571428571428577,0.03333333333333333,0.0
rate-local-sufficiency_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Mistral-7B-Instruct-v0.3,,2.87037037037037,0.1,0.0
rate-cogency_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Mistral-7B-Instruct-v0.3,,3.727272727272728,0.33333333333333337,0.0
rate-credibility_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Mistral-7B-Instruct-v0.3,,9.999999999999995,0.06666666666666667,0.0
rate-emotional-appeal_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Mistral-7B-Instruct-v0.3,,9.473684210526333,0.06666666666666667,0.0
rate-clarity_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Mistral-7B-Instruct-v0.3,,4.473684210526316,0.13333333333333333,0.0
rate-appropriateness_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Mistral-7B-Instruct-v0.3,,1.2499999999999998,0.26666666666666666,0.0
rate-arrangement_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Mistral-7B-Instruct-v0.3,,3.676470588235294,0.06666666666666667,0.0
rate-effectiveness_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Mistral-7B-Instruct-v0.3,,2.6851851851851842,0.06666666666666667,0.0
rate-global-acceptability_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Mistral-7B-Instruct-v0.3,,1.8421052631578947,0.16666666666666666,0.0
rate-global-relevance_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Mistral-7B-Instruct-v0.3,,1.8421052631578947,0.16666666666666666,0.0
rate-global-sufficiency_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Mistral-7B-Instruct-v0.3,,3.186813186813186,0.06666666666666667,0.0
rate-reasonableness_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Mistral-7B-Instruct-v0.3,,3.166666666666666,0.26666666666666666,0.0
rate-overall-quality_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,Mistral-7B-Instruct-v0.3,,1.7500000000000002,0.19999999999999998,0.0
detect-enthymemes_enthymemes-student-essays,clf,ca,enthymemes-student-essays,Mistral-7B-Instruct-v0.3,0.3333333333333333,,0.5,0.5
reconstruct-enthymemes_enthymemes-student-essays,gen,ca,enthymemes-student-essays,Mistral-7B-Instruct-v0.3,,,0.1278561138562414,0.0
classifying-argument-strength_icle-argument-strength,reg,ca,icle-argument-strength,Mistral-7B-Instruct-v0.3,,1.3079960513326754,0.52,0.0
argumentative-text-creation_microtexts,gen,ca,microtexts,Mistral-7B-Instruct-v0.3,,,0.16451369524247247,0.0
central-claim-extraction_microtexts,gen,ca,microtexts,Mistral-7B-Instruct-v0.3,,,0.3425046706810169,0.0
argumentative-role-determination_microtexts,clf,ca,microtexts,Mistral-7B-Instruct-v0.3,0.6457131288591963,,0.65,0.65
function-of-segment-determination_microtexts,clf,ca,microtexts,Mistral-7B-Instruct-v0.3,0.07253071253071253,,0.16,0.16
unit-attachment-identification_microtexts,clf,ca,microtexts,Mistral-7B-Instruct-v0.3,0.6124031007751938,,0.62,0.62
stance-prediction_belief-based-arguments,clf,ca,belief-based-arguments,Mistral-7B-Instruct-v0.3,0.15538847117794485,,0.30392156862745096,0.30392156862745096
belief-based-claim-generation_belief-based-arguments,gen,ca,belief-based-arguments,Mistral-7B-Instruct-v0.3,,,0.12904387645385257,0.0
argument-clause-recognition_echr,clf,ca,echr,Mistral-7B-Instruct-v0.3,0.47862356621480706,,0.55,0.55
clause-relation-prediction_echr,clf,ca,echr,Mistral-7B-Instruct-v0.3,0.6090225563909775,,0.9645454545454538,0.61
premise-recognition_echr,clf,ca,echr,Mistral-7B-Instruct-v0.3,0.5305164319248826,,0.57,0.57
conlusion-recognition_echr,clf,ca,echr,Mistral-7B-Instruct-v0.3,0.4350282485875706,,0.53,0.53
reason-identification_reason-identification-and-classification,gen,ca,reason-identification-and-classification,Mistral-7B-Instruct-v0.3,,,0.2437787485185753,0.0
conclusion-generation_webis-conclugen-21,gen,ca,webis-conclugen-21,Mistral-7B-Instruct-v0.3,,,0.1662766001111504,0.0
quality-assessment_ibm-rank-30k,reg,ca,ibm-rank-30k,Mistral-7B-Instruct-v0.3,,5.071028279372878,0.5,0.0
stance-prediction_ibm-rank-30k,clf,ca,ibm-rank-30k,Mistral-7B-Instruct-v0.3,0.6615351020853806,,0.69,0.69
extractive-summarization_debate-dum,gen,ca,debate-dum,Mistral-7B-Instruct-v0.3,,,0.35440119623363114,0.0
review-helpfulness-prediction_amazon-review-dataset,reg,ca,amazon-review-dataset,Mistral-7B-Instruct-v0.3,,2.8050490883590466,0.35333333333333344,0.0
unit-segmentation-prediction_amazon-review-dataset,gen,ca,amazon-review-dataset,Mistral-7B-Instruct-v0.3,,,0.5698750101665382,0.0
unit-classification-prediction_amazon-review-dataset,gen,ca,amazon-review-dataset,Mistral-7B-Instruct-v0.3,,,0.05475850336768175,0.0
relation-detection_amazon-review-dataset,clf,ca,amazon-review-dataset,Mistral-7B-Instruct-v0.3,0.5178737541528239,,0.61,0.61
classify-more-convincing-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Mistral-7B-Instruct-v0.3,0.6161616161616161,,0.81,0.62
classify-more-details-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Mistral-7B-Instruct-v0.3,0.39290917921321034,,0.5,0.5
classify-more-balanced-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Mistral-7B-Instruct-v0.3,0.47150735294117646,,0.54,0.54
classify-more-credible-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Mistral-7B-Instruct-v0.3,0.3706597222222222,,0.42,0.42
classify-more-clear-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Mistral-7B-Instruct-v0.3,0.43464495703301675,,0.5,0.5
classify-more-on-topic-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Mistral-7B-Instruct-v0.3,0.3333333333333333,,0.5,0.5
classify-more-provoking-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Mistral-7B-Instruct-v0.3,0.3922393641888733,,0.48,0.48
classify-more-smart-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Mistral-7B-Instruct-v0.3,0.5459824728117411,,0.57,0.57
classify-less-attacking-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Mistral-7B-Instruct-v0.3,0.3333333333333333,,0.5,0.5
classify-less-language-issues-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Mistral-7B-Instruct-v0.3,0.3333333333333333,,0.5,0.5
classify-less-unclear-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Mistral-7B-Instruct-v0.3,0.3333333333333333,,0.5,0.5
classify-less-facts-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Mistral-7B-Instruct-v0.3,0.3333333333333333,,0.5,0.5
classify-less-reasoning-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Mistral-7B-Instruct-v0.3,0.3333333333333333,,0.5,0.5
classify-less-relevant-reasons_ukp-convarg-2,clf,ca,ukp-convarg-2,Mistral-7B-Instruct-v0.3,0.3333333333333333,,0.5,0.5
classify-not-an-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Mistral-7B-Instruct-v0.3,0.3333333333333333,,0.5,0.5
classify-nonsense-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Mistral-7B-Instruct-v0.3,0.3333333333333333,,0.5,0.5
classify-off-topic-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Mistral-7B-Instruct-v0.3,0.3333333333333333,,0.5,0.5
classify-generally-weak-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,Mistral-7B-Instruct-v0.3,0.3333333333333333,,0.5,0.5
detect-persuasive-documents_aaugwd,clf,ca,aaugwd,Mistral-7B-Instruct-v0.3,0.719551282051282,,0.9066666666666668,0.72
extract-toulmin-components_aaugwd,gen,ca,aaugwd,Mistral-7B-Instruct-v0.3,,,0.2946524590618092,0.0
stance-detection_comarg,clf,ca,comarg,Mistral-7B-Instruct-v0.3,0.10881652694788681,,0.7775494505494501,0.21
argument-similarity_ukp-aspect-corpus,clf,ca,ukp-aspect-corpus,Mistral-7B-Instruct-v0.3,0.1693121693121693,,0.4466666666666669,0.0
argument-identification_UKP-sentential-argument-mining,clf,ca,UKP-sentential-argument-mining,Mistral-7B-Instruct-v0.3,0.4578627481150946,,0.7647058823529411,0.5294117647058824
same-debate-opposing-counters_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,Mistral-7B-Instruct-v0.3,,,0.2164484293877382,0.0
same-debate-counters_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,Mistral-7B-Instruct-v0.3,,,0.19056354375789133,0.0
same-debate-opposing-argument_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,Mistral-7B-Instruct-v0.3,,,0.1761605235395216,0.0
same-debate-argument_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,Mistral-7B-Instruct-v0.3,,,0.17984342731336217,0.0
predict-agreement_iac-v2,reg,ca,iac-v2,Mistral-7B-Instruct-v0.3,,1.756061442509223,0.285,0.0
predict-respect_iac-v2,reg,ca,iac-v2,Mistral-7B-Instruct-v0.3,,2.621054175892381,0.365,0.0
predict-factuality_iac-v2,reg,ca,iac-v2,Mistral-7B-Instruct-v0.3,,2.752546006067309,0.38,0.0
predict-nice_iac-v2,reg,ca,iac-v2,Mistral-7B-Instruct-v0.3,,3.146002604499942,0.365,0.0
predict-sarcasm_iac-v2,reg,ca,iac-v2,Mistral-7B-Instruct-v0.3,,0.9305134249475763,0.42,0.0
synthesize-argument_argumentation-synthesis,gen,ca,argumentation-synthesis,Mistral-7B-Instruct-v0.3,,,0.1622866726330837,0.0
claim-revision-improvement_claim-revision-pair-corpus,clf,ca,claim-revision-pair-corpus,Mistral-7B-Instruct-v0.3,0.4858352656517794,,0.745,0.49
suboptimal-claim-detection_claim-revision-pair-corpus,clf,ca,claim-revision-pair-corpus,Mistral-7B-Instruct-v0.3,0.5288220551378446,,0.53,0.53
claim-improvement-suggestions_claim-revision-pair-corpus,clf,ca,claim-revision-pair-corpus,Mistral-7B-Instruct-v0.3,0.06386554621848739,,0.29,0.19
claim-optimization_claim-revision-pair-corpus,gen,ca,claim-revision-pair-corpus,Mistral-7B-Instruct-v0.3,,,0.31360950721805136,0.0
aspect-controlled-argument-generation_aspect-controlled-argument-generation,gen,ca,aspect-controlled-argument-generation,Mistral-7B-Instruct-v0.3,,,0.10562608993543511,0.0
propositional-relations-identification_qt30,clf,ca,qt30,argpaca-8b,0.1,,0.25,0.25
illocutionary-relations-identification_qt30,clf,ca,qt30,argpaca-8b,0.08198024198024198,,0.26732673267326734,0.15841584158415842
argument-reasoning-comprehension_argument-reasoning-comprehension,gen,ca,argument-reasoning-comprehension,argpaca-8b,,,0.9132337592897222,0.68
inappropriateness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,argpaca-8b,0.4357638888888889,,0.48,0.48
toxic-emotions-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,argpaca-8b,0.5174632352941176,,0.86,0.58
missing-commitment-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,argpaca-8b,0.3333333333333333,,0.8333333333333335,0.5
missing-intelligibility-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,argpaca-8b,0.3333333333333333,,0.8333333333333335,0.5
other-inappropriateness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,argpaca-8b,0.19388176932616782,,0.9290909090909075,0.22
excessive-intensity-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,argpaca-8b,0.4590695997115038,,0.775,0.55
emotional-deception-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,argpaca-8b,0.3333333333333333,,0.9285714285714287,0.5
missing-seriousness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,argpaca-8b,0.3333333333333333,,0.8333333333333335,0.5
missing-openness-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,argpaca-8b,0.3333333333333333,,0.8333333333333335,0.5
unclear-meaning-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,argpaca-8b,0.3743099006256901,,0.745,0.49
missing-relevance-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,argpaca-8b,0.3333333333333333,,0.8333333333333335,0.5
confusing-reasoning-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,argpaca-8b,0.3759590792838875,,0.695,0.39
detrimental-orthography-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,argpaca-8b,0.12280701754385964,,0.57,0.14
reason-unclassified-detection_appropriateness-corpus,clf,ca,appropriateness-corpus,argpaca-8b,0.1099109910991099,,0.8219999999999986,0.11
key-point-matching_argkp,clf,ca,argkp,argpaca-8b,0.6956168831168831,,0.7,0.7
key-point-generation_argkp,gen,ca,argkp,argpaca-8b,,,0.1726401172330523,0.0
pragmatic-tagging_f1000rd,gen,ca,f1000rd,argpaca-8b,,,0.267854401054312,0.0
same-side-stance-classification_webis-sameside-19,clf,ca,webis-sameside-19,argpaca-8b,0.4025735294117647,,0.826666666666667,0.48
novelty-classification_argsvalidnovel,clf,ca,argsvalidnovel,argpaca-8b,0.5182657567242072,,0.52,0.52
validity-classification_argsvalidnovel,clf,ca,argsvalidnovel,argpaca-8b,0.7076318177235609,,0.71,0.71
relative-novelty-classification_argsvalidnovel,clf,ca,argsvalidnovel,argpaca-8b,0.18694885361552027,,0.3431372549019608,0.3431372549019608
relative-validity-classification_argsvalidnovel,clf,ca,argsvalidnovel,argpaca-8b,0.16417910447761194,,0.3235294117647059,0.3235294117647059
identifying-argument-components_argument-annotated-essays-2,gen,ca,argument-annotated-essays-2,argpaca-8b,,,0.6789984866661815,0.0
classifying-argument-components_argument-annotated-essays-2,gen,ca,argument-annotated-essays-2,argpaca-8b,,,0.04298034956654851,0.0
identifying-argumentative-relations_argument-annotated-essays-2,clf,ca,argument-annotated-essays-2,argpaca-8b,0.5151515151515151,,0.52,0.52
stance-recognition_argument-annotated-essays-2,clf,ca,argument-annotated-essays-2,argpaca-8b,0.29577464788732394,,0.42,0.42
rate-local-acceptability_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,argpaca-8b,,0.9259259259259257,0.3666666666666667,0.0
rate-local-relevance_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,argpaca-8b,,0.7142857142857144,0.4333333333333333,0.0
rate-local-sufficiency_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,argpaca-8b,,1.2962962962962958,0.19999999999999998,0.0
rate-cogency_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,argpaca-8b,,1.1818181818181823,0.26666666666666666,0.0
rate-credibility_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,argpaca-8b,,1.052631578947368,0.5999999999999999,0.0
rate-emotional-appeal_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,argpaca-8b,,1.0526315789473704,0.5999999999999999,0.0
rate-clarity_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,argpaca-8b,,1.3157894736842106,0.4999999999999999,0.0
rate-appropriateness_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,argpaca-8b,,0.769230769230769,0.4,0.0
rate-arrangement_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,argpaca-8b,,0.8823529411764705,0.4666666666666666,0.0
rate-effectiveness_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,argpaca-8b,,1.2962962962962958,0.19999999999999998,0.0
rate-global-acceptability_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,argpaca-8b,,0.8771929824561403,0.33333333333333337,0.0
rate-global-relevance_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,argpaca-8b,,1.0526315789473684,0.26666666666666666,0.0
rate-global-sufficiency_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,argpaca-8b,,1.538461538461538,0.2333333333333333,0.0
rate-reasonableness_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,argpaca-8b,,1.1666666666666665,0.2333333333333333,0.0
rate-overall-quality_dagstuhl-15512-arg-quality,reg,ca,dagstuhl-15512-arg-quality,argpaca-8b,,1.25,0.16666666666666666,0.0
detect-enthymemes_enthymemes-student-essays,clf,ca,enthymemes-student-essays,argpaca-8b,0.3776613167376351,,0.43,0.43
reconstruct-enthymemes_enthymemes-student-essays,gen,ca,enthymemes-student-essays,argpaca-8b,,,0.12745547623877063,0.0
classifying-argument-strength_icle-argument-strength,reg,ca,icle-argument-strength,argpaca-8b,,2.967140755272192,0.31,0.0
argumentative-text-creation_microtexts,gen,ca,microtexts,argpaca-8b,,,0.19241144259035614,0.0
central-claim-extraction_microtexts,gen,ca,microtexts,argpaca-8b,,,0.7276895739448334,0.45454545454545453
argumentative-role-determination_microtexts,clf,ca,microtexts,argpaca-8b,0.6693333333333333,,0.69,0.69
function-of-segment-determination_microtexts,clf,ca,microtexts,argpaca-8b,0.10394337714863497,,0.23,0.18
unit-attachment-identification_microtexts,clf,ca,microtexts,argpaca-8b,0.5452666391070691,,0.56,0.56
stance-prediction_belief-based-arguments,clf,ca,belief-based-arguments,argpaca-8b,0.2878787878787879,,0.37254901960784315,0.37254901960784315
belief-based-claim-generation_belief-based-arguments,gen,ca,belief-based-arguments,argpaca-8b,,,0.08114462729764967,0.0
argument-clause-recognition_echr,clf,ca,echr,argpaca-8b,0.5772946859903382,,0.58,0.58
clause-relation-prediction_echr,clf,ca,echr,argpaca-8b,0.3333333333333333,,0.9545454545454538,0.5
premise-recognition_echr,clf,ca,echr,argpaca-8b,0.5332792207792207,,0.54,0.54
conlusion-recognition_echr,clf,ca,echr,argpaca-8b,0.5664885573142454,,0.57,0.57
reason-identification_reason-identification-and-classification,gen,ca,reason-identification-and-classification,argpaca-8b,,,0.500096963434921,0.0
conclusion-generation_webis-conclugen-21,gen,ca,webis-conclugen-21,argpaca-8b,,,0.1758677651207852,0.0
quality-assessment_ibm-rank-30k,reg,ca,ibm-rank-30k,argpaca-8b,,4.604631604869103,0.515,0.0
stance-prediction_ibm-rank-30k,clf,ca,ibm-rank-30k,argpaca-8b,0.5151515151515151,,0.52,0.52
extractive-summarization_debate-dum,gen,ca,debate-dum,argpaca-8b,,,0.5840428351806107,0.0
review-helpfulness-prediction_amazon-review-dataset,reg,ca,amazon-review-dataset,argpaca-8b,,2.8355387523629494,0.3333333333333335,0.0
unit-segmentation-prediction_amazon-review-dataset,gen,ca,amazon-review-dataset,argpaca-8b,,,0.9664093958941771,0.1
unit-classification-prediction_amazon-review-dataset,gen,ca,amazon-review-dataset,argpaca-8b,,,0.22421595425023355,0.0
relation-detection_amazon-review-dataset,clf,ca,amazon-review-dataset,argpaca-8b,0.2866507674432826,,0.32,0.32
classify-more-convincing-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,argpaca-8b,0.5766488413547237,,0.81,0.62
classify-more-details-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,argpaca-8b,0.5198079231692677,,0.52,0.52
classify-more-balanced-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,argpaca-8b,0.5477841422972565,,0.55,0.55
classify-more-credible-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,argpaca-8b,0.4285714285714286,,0.43,0.43
classify-more-clear-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,argpaca-8b,0.48872180451127817,,0.49,0.49
classify-more-on-topic-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,argpaca-8b,0.468671679197995,,0.47,0.47
classify-more-provoking-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,argpaca-8b,0.5777983729790959,,0.59,0.59
classify-more-smart-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,argpaca-8b,0.4747474747474747,,0.48,0.48
classify-less-attacking-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,argpaca-8b,0.6637242538881883,,0.68,0.68
classify-less-language-issues-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,argpaca-8b,0.483110950835437,,0.57,0.57
classify-less-unclear-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,argpaca-8b,0.44326348820730843,,0.45,0.45
classify-less-facts-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,argpaca-8b,0.39290917921321034,,0.5,0.5
classify-less-reasoning-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,argpaca-8b,0.3551587301587301,,0.48,0.48
classify-less-relevant-reasons_ukp-convarg-2,clf,ca,ukp-convarg-2,argpaca-8b,0.467390212038991,,0.47,0.47
classify-not-an-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,argpaca-8b,0.554367201426025,,0.6,0.6
classify-nonsense-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,argpaca-8b,0.4574652777777778,,0.5,0.5
classify-off-topic-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,argpaca-8b,0.7189883580891208,,0.72,0.72
classify-generally-weak-argument_ukp-convarg-2,clf,ca,ukp-convarg-2,argpaca-8b,0.44920440636474906,,0.46,0.46
detect-persuasive-documents_aaugwd,clf,ca,aaugwd,argpaca-8b,0.5784825371336813,,0.86,0.58
extract-toulmin-components_aaugwd,gen,ca,aaugwd,argpaca-8b,,,0.4799533548545255,0.0
stance-detection_comarg,clf,ca,comarg,argpaca-8b,0.17365079365079367,,0.7035091575091572,0.23
argument-similarity_ukp-aspect-corpus,clf,ca,ukp-aspect-corpus,argpaca-8b,0.1267361111111111,,0.4166666666666668,0.0
argument-identification_UKP-sentential-argument-mining,clf,ca,UKP-sentential-argument-mining,argpaca-8b,0.27997951868919607,,0.6911764705882353,0.38235294117647056
same-debate-opposing-counters_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,argpaca-8b,,,0.23678804136698564,0.0
same-debate-counters_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,argpaca-8b,,,0.09133384546027022,0.0
same-debate-opposing-argument_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,argpaca-8b,,,0.10434830865180483,0.0
same-debate-argument_arguana-counterargs-corpus,gen,ca,arguana-counterargs-corpus,argpaca-8b,,,0.05439213723303459,0.0
predict-agreement_iac-v2,reg,ca,iac-v2,argpaca-8b,,2.047812133858285,0.235,0.0
predict-respect_iac-v2,reg,ca,iac-v2,argpaca-8b,,1.283150798572611,0.275,0.0
predict-factuality_iac-v2,reg,ca,iac-v2,argpaca-8b,,2.1485286840760276,0.33,0.0
predict-nice_iac-v2,reg,ca,iac-v2,argpaca-8b,,2.4412661207985593,0.28,0.0
predict-sarcasm_iac-v2,reg,ca,iac-v2,argpaca-8b,,5.046565435358951,0.405,0.0
synthesize-argument_argumentation-synthesis,gen,ca,argumentation-synthesis,argpaca-8b,,,0.13245056840919409,0.0
claim-revision-improvement_claim-revision-pair-corpus,clf,ca,claim-revision-pair-corpus,argpaca-8b,0.5174503422735944,,0.785,0.57
suboptimal-claim-detection_claim-revision-pair-corpus,clf,ca,claim-revision-pair-corpus,argpaca-8b,0.3551783129359126,,0.51,0.51
claim-improvement-suggestions_claim-revision-pair-corpus,clf,ca,claim-revision-pair-corpus,argpaca-8b,0.09402597402597403,,0.2025,0.2
claim-optimization_claim-revision-pair-corpus,gen,ca,claim-revision-pair-corpus,argpaca-8b,,,0.783894813298989,0.05
aspect-controlled-argument-generation_aspect-controlled-argument-generation,gen,ca,aspect-controlled-argument-generation,argpaca-8b,,,0.09836899036992577,0.0
Task1516ImppresNaturallanguageinference,clf,superni,ERROR,llama3-8b-instruct,0.16666666666666666,,0.3333333333333333,0.3333333333333333
Task1612SickLabelClassification,clf,superni,ERROR,llama3-8b-instruct,0.4673491281812659,,0.5392156862745098,0.5392156862745098
Task1409DartTextGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.4529815799397609,0.01
Task035WinograndeQuestionModificationPerson,gen,superni,ERROR,llama3-8b-instruct,,,0.7760803039139632,0.0
Task1161Coda19TitleGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.39069056281036474,0.0
Task1557JflegAnswerGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.844905537688806,0.0
Task200MnliEntailmentClassification,clf,superni,ERROR,llama3-8b-instruct,0.6742261800826496,,0.7058823529411765,0.7058823529411765
Task391CausalRelationship,clf,superni,ERROR,llama3-8b-instruct,0.5413333333333333,,0.856666666666667,0.57
Task1342AmazonUsReviewsTitle,gen,superni,ERROR,llama3-8b-instruct,,,0.1099145808143673,0.0
Task1533DailyDialogFormalClassification,clf,superni,ERROR,llama3-8b-instruct,0.3288590604026846,,0.49,0.49
Task1531DailyDialogTypeClassification,clf,superni,ERROR,llama3-8b-instruct,0.3530267977636399,,0.41,0.41
Task329GapClassification,clf,superni,ERROR,llama3-8b-instruct,0.18322672352523098,,0.3333333333333333,0.3333333333333333
Task402GrailqaParaphraseGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.45207662415209077,0.0
Task1152BardAnalogicalReasoningCausation,gen,superni,ERROR,llama3-8b-instruct,,,0.05333333333333333,0.0
Task670AmbigqaQuestionGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.6272074609470765,0.0
Task936DefeasibleNliSnliClassification,clf,superni,ERROR,llama3-8b-instruct,0.5604395604395604,,0.6,0.6
Task190SnliClassification,clf,superni,ERROR,llama3-8b-instruct,0.4027735600769309,,0.41,0.41
Task1407DartQuestionGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.20809214010986132,0.0
Task442ComQaParaphraseQuestionGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.5604998501785221,0.0
Task1622DisflQaTextModication,gen,superni,ERROR,llama3-8b-instruct,,,0.7317437415714406,0.11
Task1391WinograndeEasyAnswerGeneration,clf,superni,ERROR,llama3-8b-instruct,0.5327635327635327,,0.59,0.59
Task1529Scitail1.1Classification,clf,superni,ERROR,llama3-8b-instruct,0.7799119647859143,,0.78,0.78
Task1728WebNlgDataToText,gen,superni,ERROR,llama3-8b-instruct,,,0.4629275734736689,0.02
Task1195DisflqaDisfluentToFluentConversion,gen,superni,ERROR,llama3-8b-instruct,,,0.7423784375244267,0.15
Task510RedditTifuTitleSummarization,gen,superni,ERROR,llama3-8b-instruct,,,0.3261332657285253,0.0
Task033WinograndeAnswerGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.07354761904761904,0.03
Task671AmbigqaTextGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.43441502085387257,0.0
Task645Summarization,gen,superni,ERROR,llama3-8b-instruct,,,0.8013333333333332,0.02
Task1393SuperglueCopaTextCompletion,clf,superni,ERROR,llama3-8b-instruct,0.5584102769971899,,0.56,0.56
Task893GapFillTheBlankCoreferenceResolution,clf,superni,ERROR,llama3-8b-instruct,0.14750037365856572,,0.38,0.23
Task219RocstoriesTitleAnswerGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.19564208014208012,0.0
Task769QedSummarization,gen,superni,ERROR,llama3-8b-instruct,,,0.4740623543123544,0.0
Task1387AnliR3Entailment,clf,superni,ERROR,llama3-8b-instruct,0.37863901637486547,,0.4411764705882353,0.4411764705882353
Task1534DailyDialogQuestionClassification,clf,superni,ERROR,llama3-8b-instruct,0.3333333333333333,,0.5,0.5
Task249EnhancedWscPronounDisambiguation,gen,superni,ERROR,llama3-8b-instruct,,,0.5130634920634914,0.0
Task401NumericFusedHeadReference,gen,superni,ERROR,llama3-8b-instruct,,,0.052333333333333336,0.02
Task880SchemaGuidedDstc8Classification,clf,superni,ERROR,llama3-8b-instruct,0.19588744588744592,,0.43333333333333324,0.3
Task020MctacoSpanBasedQuestion,clf,superni,ERROR,llama3-8b-instruct,0.37600644122383253,,0.38,0.38
Task569RecipeNlgTextGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.370270142138563,0.0
Task201MnliNeutralClassification,clf,superni,ERROR,llama3-8b-instruct,0.1311111111111111,,0.16666666666666666,0.16666666666666666
Task1664WinobiasTextGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.4900678210678208,0.0
Task891GapCoreferenceResolution,gen,superni,ERROR,llama3-8b-instruct,,,0.37813708513708505,0.25
Task738PerspectrumClassification,clf,superni,ERROR,llama3-8b-instruct,0.7092731829573935,,0.71,0.71
Task648AnswerGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.368965367965368,0.02
Task1640Aqa1.0AnswerableUnanswerableQuestionClassification,clf,superni,ERROR,llama3-8b-instruct,0.628178072555522,,0.63,0.63
Task233IircLinkExistsClassification,clf,superni,ERROR,llama3-8b-instruct,0.3333333333333333,,0.5,0.5
Task520AquamuseAnswerGivenInPassage,clf,superni,ERROR,llama3-8b-instruct,0.8594941790445605,,0.86,0.86
Task619OhsumedAbstractTitleGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.3543125525522639,0.0
Task827CopaCommonsenseReasoning,clf,superni,ERROR,llama3-8b-instruct,0.7726333195535345,,0.78,0.78
Task1562ZestTextModification,gen,superni,ERROR,llama3-8b-instruct,,,0.4865960115135291,0.01
Task1157BardAnalogicalReasoningRoomsForContainers,gen,superni,ERROR,llama3-8b-instruct,,,0.23666666666666672,0.0
Task039QascFindOverlappingWords,gen,superni,ERROR,llama3-8b-instruct,,,0.42971428571428577,0.2
Task1386AnliR2Entailment,clf,superni,ERROR,llama3-8b-instruct,0.26900584795321636,,0.35294117647058826,0.35294117647058826
Task1554ScitailClassification,clf,superni,ERROR,llama3-8b-instruct,0.7631551848419318,,0.77,0.77
Task1624DisflQaQuestionYesnoClassification,clf,superni,ERROR,llama3-8b-instruct,0.5746446726838883,,0.59,0.59
Task102CommongenSentenceGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.2956038377563715,0.0
Task202MnliContradictionClassification,clf,superni,ERROR,llama3-8b-instruct,0.3191048191048191,,0.38235294117647056,0.38235294117647056
Task362SpolinYesandPromptResponseSubClassification,clf,superni,ERROR,llama3-8b-instruct,0.3333333333333333,,0.75,0.5
Task034WinograndeQuestionModificationObject,gen,superni,ERROR,llama3-8b-instruct,,,0.87326143698759,0.0
Task349Squad2.0AnswerableUnanswerableQuestionClassification,clf,superni,ERROR,llama3-8b-instruct,0.6892230576441103,,0.69,0.69
Task050MultircAnswerability,clf,superni,ERROR,llama3-8b-instruct,0.45894216917061126,,0.7,0.69
Task133WinowhyReasonPlausibilityDetection,clf,superni,ERROR,llama3-8b-instruct,0.3333333333333333,,0.5,0.5
Task642EsnliClassification,clf,superni,ERROR,llama3-8b-instruct,0.28698752228163993,,0.36,0.36
Task970SherliicCausalRelationship,clf,superni,ERROR,llama3-8b-instruct,0.49304282170208175,,0.53,0.53
Task743EurlexSummarization,gen,superni,ERROR,llama3-8b-instruct,,,0.2940910642849008,0.0
Task242TweetqaClassification,clf,superni,ERROR,llama3-8b-instruct,0.6693333333333333,,0.69,0.69
Task620OhsumedMedicalSubjectHeadingsAnswerGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.04269047619047619,0.01
Task1156BardAnalogicalReasoningTools,gen,superni,ERROR,llama3-8b-instruct,,,0.3516666666666668,0.0
Task641EsnliClassification,clf,superni,ERROR,llama3-8b-instruct,0.4310801484714528,,0.4803921568627451,0.4803921568627451
Task1356XlsumTitleGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.23932940381843518,0.0
Task1158BardAnalogicalReasoningManipulatingItems,gen,superni,ERROR,llama3-8b-instruct,,,0.23833333333333342,0.01
Task220RocstoriesTitleClassification,clf,superni,ERROR,llama3-8b-instruct,0.8894583458948849,,0.89,0.89
Task935DefeasibleNliAtomicClassification,clf,superni,ERROR,llama3-8b-instruct,0.46236559139784944,,0.54,0.54
Task1345GlueQqpQuestionParaprashing,gen,superni,ERROR,llama3-8b-instruct,,,0.3176469112188682,0.0
Task226EnglishLanguageAnswerRelevanceClassification,clf,superni,ERROR,llama3-8b-instruct,0.45725915875169604,,0.52,0.52
Task1659TitleGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.38495266023679525,0.1
Task760MsrSqaLongTextGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.3127966286623197,0.0
Task937DefeasibleNliSocialClassification,clf,superni,ERROR,llama3-8b-instruct,0.5238095238095238,,0.6,0.6
Task957E2eNlgTextGenerationGenerate,gen,superni,ERROR,llama3-8b-instruct,,,0.4697430562406626,0.0
Task1344GlueEntailmentClassification,clf,superni,ERROR,llama3-8b-instruct,0.6782496782496783,,0.7,0.7
Task892GapReverseCoreferenceResolution,clf,superni,ERROR,llama3-8b-instruct,0.24123806667666317,,0.5294117647058824,0.28431372549019607
Task1615SickTclassifyBRelationA,clf,superni,ERROR,llama3-8b-instruct,0.7783625730994151,,0.9281045751633991,0.7843137254901961
Task828CopaCommonsenseCauseEffect,clf,superni,ERROR,llama3-8b-instruct,0.3333333333333333,,0.5,0.5
Task1358XlsumTitleGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.3435731017356134,0.0
Task1385AnliR1Entailment,clf,superni,ERROR,llama3-8b-instruct,0.2473392933163048,,0.3431372549019608,0.3431372549019608
Task418PersentTitleGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.2605652757320304,0.0
Task1586ScifactTitleGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.3623328854019722,0.0
Task890GcwdClassification,clf,superni,ERROR,llama3-8b-instruct,0.4966800629040713,,0.5,0.5
Task640EsnliClassification,clf,superni,ERROR,llama3-8b-instruct,0.2497435897435897,,0.35,0.35
Task1153BardAnalogicalReasoningAffordance,gen,superni,ERROR,llama3-8b-instruct,,,0.10999999999999999,0.03
Task1439DoqaCookingIsanswerable,clf,superni,ERROR,llama3-8b-instruct,0.3710691823899371,,0.51,0.51
Task290TellmewhyQuestionAnswerability,clf,superni,ERROR,llama3-8b-instruct,0.4276736617663562,,0.8299999999999998,0.49
Task1598NycLongTextGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.2544639791345823,0.0
Task1415YoutubeCaptionCorrectionsGrammarCorrection,gen,superni,ERROR,llama3-8b-instruct,,,0.6323812431776069,0.0
Task393PlausibleResultGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.18617983558322096,0.0
Task288GigawordSummarization,gen,superni,ERROR,llama3-8b-instruct,,,0.26451180801484797,0.0
Task1388CbEntailment,clf,superni,ERROR,llama3-8b-instruct,0.26005906238464377,,0.29,0.29
Task1154BardAnalogicalReasoningTravel,gen,superni,ERROR,llama3-8b-instruct,,,0.13333333333333328,0.0
Task392InverseCausalRelationship,clf,superni,ERROR,llama3-8b-instruct,0.62996299629963,,0.8766666666666668,0.63
Task879SchemaGuidedDstc8Classification,clf,superni,ERROR,llama3-8b-instruct,0.568536342515765,,0.61,0.61
Task281PointsOfCorrespondence,gen,superni,ERROR,llama3-8b-instruct,,,0.37141816144641493,0.0
Task1442DoqaMoviesIsanswerable,clf,superni,ERROR,llama3-8b-instruct,0.33035714285714285,,0.46,0.46
Task613PolitifactTextGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.17054761904761906,0.0
Task304NumericFusedHeadResolution,gen,superni,ERROR,llama3-8b-instruct,,,0.16452380952380952,0.11
Task199MnliClassification,clf,superni,ERROR,llama3-8b-instruct,0.5182657567242072,,0.52,0.52
Task330GapAnswerGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.5882380952380951,0.47
Task1394MetaWozTaskClassification,clf,superni,ERROR,llama3-8b-instruct,0.030769230769230767,,0.06159420289855073,0.057971014492753624
Task677OllieSentenceAnswerGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.3537953472782799,0.0
Task121ZestTextModification,gen,superni,ERROR,llama3-8b-instruct,,,0.4264128105071883,0.0
Task232IircLinkNumberClassification,clf,superni,ERROR,llama3-8b-instruct,0.3333333333333333,,0.5,0.5
Task500ScruplesAnecdotesTitleGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.17931046244313287,0.0
Task623OhsumedYesNoAnswerGeneration,clf,superni,ERROR,llama3-8b-instruct,0.5071523019593701,,0.59,0.59
Task1390WscfixedCoreference,clf,superni,ERROR,llama3-8b-instruct,0.49269480519480524,,0.5,0.5
Task1159BardAnalogicalReasoningContainers,gen,superni,ERROR,llama3-8b-instruct,,,0.19833333333333333,0.0
Task614GlucoseCauseEventDetection,gen,superni,ERROR,llama3-8b-instruct,,,0.38884712914356684,0.0
Task1540ParsedPdfsSummarization,gen,superni,ERROR,llama3-8b-instruct,,,0.382125766840201,0.0
Task602Wikitext-103AnswerGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.11897310011805809,0.0
Task1155BardAnalogicalReasoningTrashOrTreasure,clf,superni,ERROR,llama3-8b-instruct,0.5017958521608157,,0.57,0.57
Task1631OpenpiAnswerGeneration,gen,superni,ERROR,llama3-8b-instruct,,,0.4867492774844576,0.0
Task036QascTopicWordToGenerateRelatedFact,gen,superni,ERROR,llama3-8b-instruct,,,0.24247294372294362,0.0
Task1516ImppresNaturallanguageinference,clf,superni,ERROR,alpaca,0.18767274737423992,,0.33980582524271846,0.33980582524271846
Task1612SickLabelClassification,clf,superni,ERROR,alpaca,0.1851851851851852,,0.33980582524271846,0.33980582524271846
Task1409DartTextGeneration,gen,superni,ERROR,alpaca,,,0.4141129273459682,0.009900990099009901
Task035WinograndeQuestionModificationPerson,gen,superni,ERROR,alpaca,,,0.8475737592844917,0.0
Task1161Coda19TitleGeneration,gen,superni,ERROR,alpaca,,,0.339801657714947,0.0
Task1557JflegAnswerGeneration,gen,superni,ERROR,alpaca,,,0.8162720561397542,0.0
Task200MnliEntailmentClassification,clf,superni,ERROR,alpaca,0.44837552598830266,,0.5145631067961165,0.5145631067961165
Task391CausalRelationship,clf,superni,ERROR,alpaca,0.6237254901960785,,0.874587458745875,0.6237623762376238
Task1342AmazonUsReviewsTitle,gen,superni,ERROR,alpaca,,,0.10900547459077121,0.0
Task1533DailyDialogFormalClassification,clf,superni,ERROR,alpaca,0.33112582781456956,,0.49504950495049505,0.49504950495049505
Task1531DailyDialogTypeClassification,clf,superni,ERROR,alpaca,0.28599528325555723,,0.36633663366336633,0.36633663366336633
Task329GapClassification,clf,superni,ERROR,alpaca,0.1893639207507821,,0.34951456310679613,0.34951456310679613
Task402GrailqaParaphraseGeneration,gen,superni,ERROR,alpaca,,,0.4586048660620328,0.0
Task1152BardAnalogicalReasoningCausation,gen,superni,ERROR,alpaca,,,0.12211221122112208,0.009900990099009901
Task670AmbigqaQuestionGeneration,gen,superni,ERROR,alpaca,,,0.605106310566615,0.0
Task936DefeasibleNliSnliClassification,clf,superni,ERROR,alpaca,0.6115384615384616,,0.6435643564356436,0.6435643564356436
Task190SnliClassification,clf,superni,ERROR,alpaca,0.3950908198330879,,0.39603960396039606,0.39603960396039606
Task1407DartQuestionGeneration,gen,superni,ERROR,alpaca,,,0.24243661978075487,0.0
Task442ComQaParaphraseQuestionGeneration,gen,superni,ERROR,alpaca,,,0.5312345869364175,0.0
Task1622DisflQaTextModication,gen,superni,ERROR,alpaca,,,0.7407662835912696,0.13861386138613863
Task1391WinograndeEasyAnswerGeneration,clf,superni,ERROR,alpaca,0.4739583333333333,,0.5445544554455446,0.5445544554455446
Task1529Scitail1.1Classification,clf,superni,ERROR,alpaca,0.4128633271490414,,0.5346534653465347,0.5346534653465347
Task1728WebNlgDataToText,gen,superni,ERROR,alpaca,,,0.45851772517516304,0.0
Task1195DisflqaDisfluentToFluentConversion,gen,superni,ERROR,alpaca,,,0.711994832088541,0.10891089108910891
Task510RedditTifuTitleSummarization,gen,superni,ERROR,alpaca,,,0.3444039273290451,0.0
Task033WinograndeAnswerGeneration,gen,superni,ERROR,alpaca,,,0.06936265055076937,0.0
Task671AmbigqaTextGeneration,gen,superni,ERROR,alpaca,,,0.48966433514505625,0.0
Task645Summarization,gen,superni,ERROR,alpaca,,,0.6935093509350932,0.019801980198019802
Task1393SuperglueCopaTextCompletion,clf,superni,ERROR,alpaca,0.5353535353535354,,0.54,0.54
Task893GapFillTheBlankCoreferenceResolution,clf,superni,ERROR,alpaca,0.09343278463648834,,0.4,0.22
Task219RocstoriesTitleAnswerGeneration,gen,superni,ERROR,alpaca,,,0.20543147721365537,0.0
Task769QedSummarization,gen,superni,ERROR,alpaca,,,0.47245845463667235,0.039603960396039604
Task1387AnliR3Entailment,clf,superni,ERROR,alpaca,0.2931839402427638,,0.3786407766990291,0.3786407766990291
Task1534DailyDialogQuestionClassification,clf,superni,ERROR,alpaca,0.35256410256410253,,0.504950495049505,0.504950495049505
Task249EnhancedWscPronounDisambiguation,gen,superni,ERROR,alpaca,,,0.49717114568599663,0.0
Task401NumericFusedHeadReference,gen,superni,ERROR,alpaca,,,0.01338991041961339,0.0
Task880SchemaGuidedDstc8Classification,clf,superni,ERROR,alpaca,0.08756957328385899,,0.3168316831683169,0.1782178217821782
Task020MctacoSpanBasedQuestion,clf,superni,ERROR,alpaca,0.22077922077922077,,0.49,0.41
Task569RecipeNlgTextGeneration,gen,superni,ERROR,alpaca,,,0.3560878978552092,0.009900990099009901
Task201MnliNeutralClassification,clf,superni,ERROR,alpaca,0.2548573163327262,,0.33980582524271846,0.33980582524271846
Task1664WinobiasTextGeneration,gen,superni,ERROR,alpaca,,,0.4830611632591827,0.0
Task891GapCoreferenceResolution,gen,superni,ERROR,alpaca,,,0.14962698412698416,0.05
Task738PerspectrumClassification,clf,superni,ERROR,alpaca,0.7425490196078431,,0.7425742574257426,0.7425742574257426
Task648AnswerGeneration,gen,superni,ERROR,alpaca,,,0.33877189916793854,0.039603960396039604
Task1640Aqa1.0AnswerableUnanswerableQuestionClassification,clf,superni,ERROR,alpaca,0.5095016891891893,,0.5445544554455446,0.5445544554455446
Task233IircLinkExistsClassification,clf,superni,ERROR,alpaca,0.35256410256410253,,0.504950495049505,0.504950495049505
Task520AquamuseAnswerGivenInPassage,clf,superni,ERROR,alpaca,0.6362045898940002,,0.6534653465346535,0.6534653465346535
Task619OhsumedAbstractTitleGeneration,gen,superni,ERROR,alpaca,,,0.3383313221467338,0.0
Task827CopaCommonsenseReasoning,clf,superni,ERROR,alpaca,0.6736026111791106,,0.68,0.68
Task1562ZestTextModification,gen,superni,ERROR,alpaca,,,0.49986982327039203,0.0
Task1157BardAnalogicalReasoningRoomsForContainers,gen,superni,ERROR,alpaca,,,0.21782178217821785,0.0
Task039QascFindOverlappingWords,gen,superni,ERROR,alpaca,,,0.22857142857142856,0.009900990099009901
Task1386AnliR2Entailment,clf,superni,ERROR,alpaca,0.21180327868852458,,0.32038834951456313,0.32038834951456313
Task1554ScitailClassification,clf,superni,ERROR,alpaca,0.35256410256410253,,0.504950495049505,0.504950495049505
Task1624DisflQaQuestionYesnoClassification,clf,superni,ERROR,alpaca,0.4647465437788018,,0.5445544554455446,0.5445544554455446
Task102CommongenSentenceGeneration,gen,superni,ERROR,alpaca,,,0.3150676401738106,0.0
Task202MnliContradictionClassification,clf,superni,ERROR,alpaca,0.3209876543209877,,0.3883495145631068,0.3883495145631068
Task362SpolinYesandPromptResponseSubClassification,clf,superni,ERROR,alpaca,0.437359250918573,,0.7673267326732673,0.5346534653465347
Task034WinograndeQuestionModificationObject,gen,superni,ERROR,alpaca,,,0.8856843009671939,0.0
Task349Squad2.0AnswerableUnanswerableQuestionClassification,clf,superni,ERROR,alpaca,0.6624895572263994,,0.6831683168316832,0.6831683168316832
Task050MultircAnswerability,clf,superni,ERROR,alpaca,0.17628205128205127,,0.504950495049505,0.49504950495049505
Task133WinowhyReasonPlausibilityDetection,clf,superni,ERROR,alpaca,0.35256410256410253,,0.504950495049505,0.504950495049505
Task642EsnliClassification,clf,superni,ERROR,alpaca,0.35542464408443786,,0.3564356435643564,0.3564356435643564
Task970SherliicCausalRelationship,clf,superni,ERROR,alpaca,0.4858181818181818,,0.5148514851485149,0.5148514851485149
Task743EurlexSummarization,gen,superni,ERROR,alpaca,,,0.28778829015147483,0.0
Task242TweetqaClassification,clf,superni,ERROR,alpaca,0.3710691823899371,,0.51,0.51
Task620OhsumedMedicalSubjectHeadingsAnswerGeneration,gen,superni,ERROR,alpaca,,,0.03558070092723558,0.0
Task1156BardAnalogicalReasoningTools,gen,superni,ERROR,alpaca,,,0.31188118811881205,0.0
Task641EsnliClassification,clf,superni,ERROR,alpaca,0.18694885361552027,,0.3431372549019608,0.3431372549019608
Task1356XlsumTitleGeneration,gen,superni,ERROR,alpaca,,,0.23115671796227136,0.0
Task1158BardAnalogicalReasoningManipulatingItems,gen,superni,ERROR,alpaca,,,0.3066666666666668,0.07
Task220RocstoriesTitleClassification,clf,superni,ERROR,alpaca,0.3733063188552615,,0.5148514851485149,0.5148514851485149
Task935DefeasibleNliAtomicClassification,clf,superni,ERROR,alpaca,0.5095016891891893,,0.5445544554455446,0.5445544554455446
Task1345GlueQqpQuestionParaprashing,gen,superni,ERROR,alpaca,,,0.31635903330895637,0.0
Task226EnglishLanguageAnswerRelevanceClassification,clf,superni,ERROR,alpaca,0.5914964979777054,,0.594059405940594,0.594059405940594
Task1659TitleGeneration,gen,superni,ERROR,alpaca,,,0.39092586934880186,0.06930693069306931
Task760MsrSqaLongTextGeneration,gen,superni,ERROR,alpaca,,,0.300374961248271,0.0
Task937DefeasibleNliSocialClassification,clf,superni,ERROR,alpaca,0.6805428017549229,,0.693069306930693,0.693069306930693
Task957E2eNlgTextGenerationGenerate,gen,superni,ERROR,alpaca,,,0.4688079458583921,0.0
Task1344GlueEntailmentClassification,clf,superni,ERROR,alpaca,0.5949197860962567,,0.6435643564356436,0.6435643564356436
Task892GapReverseCoreferenceResolution,clf,superni,ERROR,alpaca,0.1645563617394603,,0.6019417475728155,0.2621359223300971
Task1615SickTclassifyBRelationA,clf,superni,ERROR,alpaca,0.6046598468332496,,0.877022653721683,0.6310679611650486
Task828CopaCommonsenseCauseEffect,clf,superni,ERROR,alpaca,0.3355263157894737,,0.504950495049505,0.504950495049505
Task1358XlsumTitleGeneration,gen,superni,ERROR,alpaca,,,0.3186525753822499,0.0
Task1385AnliR1Entailment,clf,superni,ERROR,alpaca,0.19846716998398536,,0.3106796116504854,0.3106796116504854
Task418PersentTitleGeneration,gen,superni,ERROR,alpaca,,,0.2529210569384149,0.0
Task1586ScifactTitleGeneration,gen,superni,ERROR,alpaca,,,0.332990338342532,0.0
Task890GcwdClassification,clf,superni,ERROR,alpaca,0.1851851851851852,,0.33980582524271846,0.33980582524271846
Task640EsnliClassification,clf,superni,ERROR,alpaca,0.23400547106473582,,0.37,0.37
Task1153BardAnalogicalReasoningAffordance,gen,superni,ERROR,alpaca,,,0.132013201320132,0.0297029702970297
Task1439DoqaCookingIsanswerable,clf,superni,ERROR,alpaca,0.48272856053176416,,0.5346534653465347,0.5346534653465347
Task290TellmewhyQuestionAnswerability,clf,superni,ERROR,alpaca,0.3355263157894737,,0.8349834983498352,0.504950495049505
Task1598NycLongTextGeneration,gen,superni,ERROR,alpaca,,,0.2914356639978241,0.0
Task1415YoutubeCaptionCorrectionsGrammarCorrection,gen,superni,ERROR,alpaca,,,0.7822949254515231,0.0
Task393PlausibleResultGeneration,gen,superni,ERROR,alpaca,,,0.14408037058015696,0.0
Task288GigawordSummarization,gen,superni,ERROR,alpaca,,,0.25756425880618244,0.0
Task1388CbEntailment,clf,superni,ERROR,alpaca,0.21311291048133152,,0.24752475247524752,0.24752475247524752
Task1154BardAnalogicalReasoningTravel,gen,superni,ERROR,alpaca,,,0.11881188118811878,0.0
Task392InverseCausalRelationship,clf,superni,ERROR,alpaca,0.7087600676145969,,0.9042904290429046,0.7128712871287128
Task879SchemaGuidedDstc8Classification,clf,superni,ERROR,alpaca,0.5457271364317842,,0.5544554455445545,0.5544554455445545
Task281PointsOfCorrespondence,gen,superni,ERROR,alpaca,,,0.30393626567776433,0.0
Task1442DoqaMoviesIsanswerable,clf,superni,ERROR,alpaca,0.46403301886792453,,0.46534653465346537,0.46534653465346537
Task613PolitifactTextGeneration,gen,superni,ERROR,alpaca,,,0.19636963696369633,0.0
Task304NumericFusedHeadResolution,gen,superni,ERROR,alpaca,,,0.07780278027802781,0.019801980198019802
Task199MnliClassification,clf,superni,ERROR,alpaca,0.3375981077303516,,0.39603960396039606,0.39603960396039606
Task330GapAnswerGeneration,gen,superni,ERROR,alpaca,,,0.32187647336162184,0.19801980198019803
Task1394MetaWozTaskClassification,clf,superni,ERROR,alpaca,0.015069200578392894,,0.12355072463768119,0.050724637681159424
Task677OllieSentenceAnswerGeneration,gen,superni,ERROR,alpaca,,,0.33433002623963454,0.0
Task121ZestTextModification,gen,superni,ERROR,alpaca,,,0.4192147805495478,0.0
Task232IircLinkNumberClassification,clf,superni,ERROR,alpaca,0.35256410256410253,,0.504950495049505,0.504950495049505
Task500ScruplesAnecdotesTitleGeneration,gen,superni,ERROR,alpaca,,,0.1415349515375088,0.0
Task623OhsumedYesNoAnswerGeneration,clf,superni,ERROR,alpaca,0.2964485554413612,,0.39603960396039606,0.39603960396039606
Task1390WscfixedCoreference,clf,superni,ERROR,alpaca,0.3988856527795365,,0.5346534653465347,0.5346534653465347
Task1159BardAnalogicalReasoningContainers,gen,superni,ERROR,alpaca,,,0.15676567656765672,0.0
Task614GlucoseCauseEventDetection,gen,superni,ERROR,alpaca,,,0.3148683221910261,0.0
Task1540ParsedPdfsSummarization,gen,superni,ERROR,alpaca,,,0.32015357458664956,0.0
Task602Wikitext-103AnswerGeneration,gen,superni,ERROR,alpaca,,,0.15234817314649243,0.011904761904761904
Task1155BardAnalogicalReasoningTrashOrTreasure,clf,superni,ERROR,alpaca,0.3355263157894737,,0.504950495049505,0.504950495049505
Task1631OpenpiAnswerGeneration,gen,superni,ERROR,alpaca,,,0.425471955640342,0.0
Task036QascTopicWordToGenerateRelatedFact,gen,superni,ERROR,alpaca,,,0.2193975468975468,0.0
Task1516ImppresNaturallanguageinference,clf,superni,ERROR,gemma-2-9b-it,0.16666666666666666,,0.3333333333333333,0.3333333333333333
Task1612SickLabelClassification,clf,superni,ERROR,gemma-2-9b-it,0.7587875796723513,,0.7647058823529411,0.7647058823529411
Task1409DartTextGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.4125052340987637,0.0
Task035WinograndeQuestionModificationPerson,gen,superni,ERROR,gemma-2-9b-it,,,0.612741950885424,0.0
Task1161Coda19TitleGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.17006687177131585,0.0
Task1557JflegAnswerGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.7050843212098187,0.0
Task200MnliEntailmentClassification,clf,superni,ERROR,gemma-2-9b-it,0.8031467557783346,,0.803921568627451,0.803921568627451
Task391CausalRelationship,clf,superni,ERROR,gemma-2-9b-it,0.7564935064935066,,0.92,0.76
Task1342AmazonUsReviewsTitle,gen,superni,ERROR,gemma-2-9b-it,,,0.02200828535307231,0.0
Task1533DailyDialogFormalClassification,clf,superni,ERROR,gemma-2-9b-it,0.5327635327635327,,0.59,0.59
Task1531DailyDialogTypeClassification,clf,superni,ERROR,gemma-2-9b-it,0.6345866360728689,,0.64,0.64
Task329GapClassification,clf,superni,ERROR,gemma-2-9b-it,0.24189261031366294,,0.37254901960784315,0.37254901960784315
Task402GrailqaParaphraseGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.45620281229545734,0.0
Task1152BardAnalogicalReasoningCausation,gen,superni,ERROR,gemma-2-9b-it,,,0.45,0.0
Task670AmbigqaQuestionGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.38164617615586216,0.0
Task936DefeasibleNliSnliClassification,clf,superni,ERROR,gemma-2-9b-it,0.8090644156366193,,0.81,0.81
Task190SnliClassification,clf,superni,ERROR,gemma-2-9b-it,0.48717948717948717,,0.55,0.55
Task1407DartQuestionGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.1682459468821855,0.0
Task442ComQaParaphraseQuestionGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.48389164406285134,0.0
Task1622DisflQaTextModication,gen,superni,ERROR,gemma-2-9b-it,,,0.6147394889703438,0.0
Task1391WinograndeEasyAnswerGeneration,clf,superni,ERROR,gemma-2-9b-it,0.849624060150376,,0.85,0.85
Task1529Scitail1.1Classification,clf,superni,ERROR,gemma-2-9b-it,0.8599439775910365,,0.86,0.86
Task1728WebNlgDataToText,gen,superni,ERROR,gemma-2-9b-it,,,0.5475700834784766,0.0
Task1195DisflqaDisfluentToFluentConversion,gen,superni,ERROR,gemma-2-9b-it,,,0.6246666665886405,0.0
Task510RedditTifuTitleSummarization,gen,superni,ERROR,gemma-2-9b-it,,,0.37017700369582385,0.0
Task033WinograndeAnswerGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.7533333333333334,0.0
Task671AmbigqaTextGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.48921724084248647,0.0
Task645Summarization,gen,superni,ERROR,gemma-2-9b-it,,,0.9158705738705738,0.0
Task1393SuperglueCopaTextCompletion,clf,superni,ERROR,gemma-2-9b-it,0.92,,0.92,0.92
Task893GapFillTheBlankCoreferenceResolution,clf,superni,ERROR,gemma-2-9b-it,0.28959532431230545,,0.83,0.36
Task219RocstoriesTitleAnswerGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.2867142857142857,0.0
Task769QedSummarization,gen,superni,ERROR,gemma-2-9b-it,,,0.7030245310245309,0.0
Task1387AnliR3Entailment,clf,superni,ERROR,gemma-2-9b-it,0.5651282590412111,,0.5588235294117647,0.5588235294117647
Task1534DailyDialogQuestionClassification,clf,superni,ERROR,gemma-2-9b-it,0.6349153667441089,,0.67,0.67
Task249EnhancedWscPronounDisambiguation,gen,superni,ERROR,gemma-2-9b-it,,,0.13258080808080813,0.0
Task401NumericFusedHeadReference,gen,superni,ERROR,gemma-2-9b-it,,,0.3,0.0
Task880SchemaGuidedDstc8Classification,clf,superni,ERROR,gemma-2-9b-it,0.22349813928761297,,0.49999999999999983,0.34
Task020MctacoSpanBasedQuestion,clf,superni,ERROR,gemma-2-9b-it,0.0,,0.55,0.0
Task569RecipeNlgTextGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.3820974299178633,0.0
Task201MnliNeutralClassification,clf,superni,ERROR,gemma-2-9b-it,0.1713365539452496,,0.18627450980392157,0.18627450980392157
Task1664WinobiasTextGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.6421904761904755,0.0
Task891GapCoreferenceResolution,gen,superni,ERROR,gemma-2-9b-it,,,0.010611111111111111,0.0
Task738PerspectrumClassification,clf,superni,ERROR,gemma-2-9b-it,0.818840579710145,,0.82,0.82
Task648AnswerGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.5179047619047616,0.0
Task1640Aqa1.0AnswerableUnanswerableQuestionClassification,clf,superni,ERROR,gemma-2-9b-it,0.7647058823529411,,0.77,0.77
Task233IircLinkExistsClassification,clf,superni,ERROR,gemma-2-9b-it,0.44317065181788406,,0.49,0.49
Task520AquamuseAnswerGivenInPassage,clf,superni,ERROR,gemma-2-9b-it,0.8886526976414617,,0.89,0.89
Task619OhsumedAbstractTitleGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.17164207221041516,0.0
Task827CopaCommonsenseReasoning,clf,superni,ERROR,gemma-2-9b-it,0.9399759903961584,,0.94,0.94
Task1562ZestTextModification,gen,superni,ERROR,gemma-2-9b-it,,,0.5101793436448437,0.0
Task1157BardAnalogicalReasoningRoomsForContainers,gen,superni,ERROR,gemma-2-9b-it,,,0.11999999999999997,0.0
Task039QascFindOverlappingWords,gen,superni,ERROR,gemma-2-9b-it,,,0.04000000000000001,0.0
Task1386AnliR2Entailment,clf,superni,ERROR,gemma-2-9b-it,0.4886904761904762,,0.49019607843137253,0.49019607843137253
Task1554ScitailClassification,clf,superni,ERROR,gemma-2-9b-it,0.8899009108197378,,0.89,0.89
Task1624DisflQaQuestionYesnoClassification,clf,superni,ERROR,gemma-2-9b-it,0.3710691823899371,,0.51,0.51
Task102CommongenSentenceGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.31697052426535016,0.0
Task202MnliContradictionClassification,clf,superni,ERROR,gemma-2-9b-it,0.8922501757815849,,0.8921568627450981,0.8921568627450981
Task362SpolinYesandPromptResponseSubClassification,clf,superni,ERROR,gemma-2-9b-it,0.7992773986350863,,0.9,0.8
Task034WinograndeQuestionModificationObject,gen,superni,ERROR,gemma-2-9b-it,,,0.8590407786912847,0.0
Task349Squad2.0AnswerableUnanswerableQuestionClassification,clf,superni,ERROR,gemma-2-9b-it,0.9197109594540345,,0.92,0.92
Task050MultircAnswerability,clf,superni,ERROR,gemma-2-9b-it,0.0,,0.72,0.0
Task133WinowhyReasonPlausibilityDetection,clf,superni,ERROR,gemma-2-9b-it,0.6427070197562001,,0.66,0.66
Task642EsnliClassification,clf,superni,ERROR,gemma-2-9b-it,0.45978391356542614,,0.46,0.46
Task970SherliicCausalRelationship,clf,superni,ERROR,gemma-2-9b-it,0.6846709388668497,,0.69,0.69
Task743EurlexSummarization,gen,superni,ERROR,gemma-2-9b-it,,,0.17044790918478855,0.0
Task242TweetqaClassification,clf,superni,ERROR,gemma-2-9b-it,0.9499949994999499,,0.95,0.95
Task620OhsumedMedicalSubjectHeadingsAnswerGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.03649206349206349,0.0
Task1156BardAnalogicalReasoningTools,gen,superni,ERROR,gemma-2-9b-it,,,0.03333333333333333,0.0
Task641EsnliClassification,clf,superni,ERROR,gemma-2-9b-it,0.3888123598843962,,0.4019607843137255,0.4019607843137255
Task1356XlsumTitleGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.12019697626676316,0.0
Task1158BardAnalogicalReasoningManipulatingItems,gen,superni,ERROR,gemma-2-9b-it,,,0.20666666666666667,0.0
Task220RocstoriesTitleClassification,clf,superni,ERROR,gemma-2-9b-it,0.98,,0.98,0.98
Task935DefeasibleNliAtomicClassification,clf,superni,ERROR,gemma-2-9b-it,0.7785829307568438,,0.78,0.78
Task1345GlueQqpQuestionParaprashing,gen,superni,ERROR,gemma-2-9b-it,,,0.23511348308097105,0.0
Task226EnglishLanguageAnswerRelevanceClassification,clf,superni,ERROR,gemma-2-9b-it,0.62,,0.62,0.62
Task1659TitleGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.1306359781515003,0.0
Task760MsrSqaLongTextGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.21758327059250146,0.0
Task937DefeasibleNliSocialClassification,clf,superni,ERROR,gemma-2-9b-it,0.7660461804495982,,0.77,0.77
Task957E2eNlgTextGenerationGenerate,gen,superni,ERROR,gemma-2-9b-it,,,0.37823155572777023,0.0
Task1344GlueEntailmentClassification,clf,superni,ERROR,gemma-2-9b-it,0.8798076923076923,,0.88,0.88
Task892GapReverseCoreferenceResolution,clf,superni,ERROR,gemma-2-9b-it,0.3936797359019581,,0.5784313725490197,0.4019607843137255
Task1615SickTclassifyBRelationA,clf,superni,ERROR,gemma-2-9b-it,0.787936507936508,,0.9346405228758173,0.803921568627451
Task828CopaCommonsenseCauseEffect,clf,superni,ERROR,gemma-2-9b-it,0.3041632267956127,,0.41,0.41
Task1358XlsumTitleGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.23631820478349647,0.0
Task1385AnliR1Entailment,clf,superni,ERROR,gemma-2-9b-it,0.7238624552057388,,0.7254901960784313,0.7254901960784313
Task418PersentTitleGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.213976685934868,0.0
Task1586ScifactTitleGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.17316776044882434,0.0
Task890GcwdClassification,clf,superni,ERROR,gemma-2-9b-it,0.4390980178214221,,0.49019607843137253,0.49019607843137253
Task640EsnliClassification,clf,superni,ERROR,gemma-2-9b-it,0.5192340947758903,,0.57,0.57
Task1153BardAnalogicalReasoningAffordance,gen,superni,ERROR,gemma-2-9b-it,,,0.25,0.0
Task1439DoqaCookingIsanswerable,clf,superni,ERROR,gemma-2-9b-it,0.7297567811029927,,0.73,0.73
Task290TellmewhyQuestionAnswerability,clf,superni,ERROR,gemma-2-9b-it,0.6072757337742869,,0.8733333333333335,0.62
Task1598NycLongTextGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.31044856898021733,0.0
Task1415YoutubeCaptionCorrectionsGrammarCorrection,gen,superni,ERROR,gemma-2-9b-it,,,0.9664197145416802,0.0
Task393PlausibleResultGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.15556808390554513,0.0
Task288GigawordSummarization,gen,superni,ERROR,gemma-2-9b-it,,,0.10217887393801851,0.0
Task1388CbEntailment,clf,superni,ERROR,gemma-2-9b-it,0.6808627849817781,,0.75,0.75
Task1154BardAnalogicalReasoningTravel,gen,superni,ERROR,gemma-2-9b-it,,,0.08,0.0
Task392InverseCausalRelationship,clf,superni,ERROR,gemma-2-9b-it,0.7889659330720531,,0.9300000000000003,0.79
Task879SchemaGuidedDstc8Classification,clf,superni,ERROR,gemma-2-9b-it,0.8782467532467533,,0.88,0.88
Task281PointsOfCorrespondence,gen,superni,ERROR,gemma-2-9b-it,,,0.5628575362770846,0.0
Task1442DoqaMoviesIsanswerable,clf,superni,ERROR,gemma-2-9b-it,0.6862030569895738,,0.69,0.69
Task613PolitifactTextGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.1367051282051282,0.0
Task304NumericFusedHeadResolution,gen,superni,ERROR,gemma-2-9b-it,,,0.43133333333333335,0.0
Task199MnliClassification,clf,superni,ERROR,gemma-2-9b-it,0.5829518868884143,,0.59,0.59
Task330GapAnswerGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.7906666666666665,0.0
Task1394MetaWozTaskClassification,clf,superni,ERROR,gemma-2-9b-it,0.606838905775076,,0.5905797101449275,0.5797101449275363
Task677OllieSentenceAnswerGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.3409906550145454,0.0
Task121ZestTextModification,gen,superni,ERROR,gemma-2-9b-it,,,0.40853024583600417,0.0
Task232IircLinkNumberClassification,clf,superni,ERROR,gemma-2-9b-it,0.5219204557013528,,0.53,0.53
Task500ScruplesAnecdotesTitleGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.04797328806438452,0.0
Task623OhsumedYesNoAnswerGeneration,clf,superni,ERROR,gemma-2-9b-it,0.9194847020933977,,0.92,0.92
Task1390WscfixedCoreference,clf,superni,ERROR,gemma-2-9b-it,0.6186270574066639,,0.62,0.62
Task1159BardAnalogicalReasoningContainers,gen,superni,ERROR,gemma-2-9b-it,,,0.1133333333333333,0.0
Task614GlucoseCauseEventDetection,gen,superni,ERROR,gemma-2-9b-it,,,0.3658518255843371,0.0
Task1540ParsedPdfsSummarization,gen,superni,ERROR,gemma-2-9b-it,,,0.09349815287596443,0.0
Task602Wikitext-103AnswerGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.12565965780251492,0.0
Task1155BardAnalogicalReasoningTrashOrTreasure,clf,superni,ERROR,gemma-2-9b-it,0.6833715471121302,,0.71,0.71
Task1631OpenpiAnswerGeneration,gen,superni,ERROR,gemma-2-9b-it,,,0.4584813923018405,0.0
Task036QascTopicWordToGenerateRelatedFact,gen,superni,ERROR,gemma-2-9b-it,,,0.25187301587301586,0.0
Task1516ImppresNaturallanguageinference,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.16666666666666666,,0.3333333333333333,0.3333333333333333
Task1612SickLabelClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.6633533034103242,,0.6568627450980392,0.6568627450980392
Task1409DartTextGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.3011228619972006,0.0
Task035WinograndeQuestionModificationPerson,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.40763667069958953,0.0
Task1161Coda19TitleGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.23558247005541463,0.0
Task1557JflegAnswerGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.65421040973595,0.0
Task200MnliEntailmentClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.16666666666666666,,0.3333333333333333,0.3333333333333333
Task391CausalRelationship,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.37629937629937626,,0.8400000000000003,0.52
Task1342AmazonUsReviewsTitle,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.12623444208085477,0.0
Task1533DailyDialogFormalClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.38557993730407525,,0.51,0.51
Task1531DailyDialogTypeClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.45950772200772205,,0.49,0.49
Task329GapClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.16666666666666666,,0.3333333333333333,0.3333333333333333
Task402GrailqaParaphraseGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.28973153095508775,0.0
Task1152BardAnalogicalReasoningCausation,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.13333333333333333,0.12
Task670AmbigqaQuestionGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.25181808984076176,0.0
Task936DefeasibleNliSnliClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.4590695997115038,,0.55,0.55
Task190SnliClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.32001255361439485,,0.35,0.35
Task1407DartQuestionGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.17425320939287442,0.0
Task442ComQaParaphraseQuestionGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.32341815383223477,0.0
Task1622DisflQaTextModication,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.5503729769218718,0.0
Task1391WinograndeEasyAnswerGeneration,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.5882166613873931,,0.61,0.61
Task1529Scitail1.1Classification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.84,,0.84,0.84
Task1728WebNlgDataToText,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.4343567470141129,0.01
Task1195DisflqaDisfluentToFluentConversion,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.5005418145086143,0.0
Task510RedditTifuTitleSummarization,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.26278436273715017,0.0
Task033WinograndeAnswerGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.43333333333333335,0.36
Task671AmbigqaTextGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.31972177739451135,0.0
Task645Summarization,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.37323465423465435,0.0
Task1393SuperglueCopaTextCompletion,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.5703301673450927,,0.62,0.62
Task893GapFillTheBlankCoreferenceResolution,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.06137651099513805,,0.39,0.14
Task219RocstoriesTitleAnswerGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.02257020757020757,0.0
Task769QedSummarization,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.16726781388546091,0.0
Task1387AnliR3Entailment,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.36612954946288284,,0.4411764705882353,0.4411764705882353
Task1534DailyDialogQuestionClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.5577607593571352,,0.59,0.59
Task249EnhancedWscPronounDisambiguation,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.1127673992673993,0.0
Task401NumericFusedHeadReference,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.21,0.17
Task880SchemaGuidedDstc8Classification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.06666666666666667,,0.33333333333333337,0.2
Task020MctacoSpanBasedQuestion,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.5543293718166383,,0.58,0.58
Task569RecipeNlgTextGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.050045643949741495,0.0
Task201MnliNeutralClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.16666666666666666,,0.3333333333333333,0.3333333333333333
Task1664WinobiasTextGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.36532933732933726,0.0
Task891GapCoreferenceResolution,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.001818181818181818,0.0
Task738PerspectrumClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.3333333333333333,,0.5,0.5
Task648AnswerGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.3098464868464868,0.05
Task1640Aqa1.0AnswerableUnanswerableQuestionClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.7799119647859143,,0.78,0.78
Task233IircLinkExistsClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.3503118503118503,,0.5,0.5
Task520AquamuseAnswerGivenInPassage,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.8782467532467533,,0.88,0.88
Task619OhsumedAbstractTitleGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.21447624959214293,0.0
Task827CopaCommonsenseReasoning,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.8897243107769424,,0.89,0.89
Task1562ZestTextModification,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.21805982084769282,0.0
Task1157BardAnalogicalReasoningRoomsForContainers,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.0,0.0
Task039QascFindOverlappingWords,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.0,0.0
Task1386AnliR2Entailment,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.27419354838709675,,0.3627450980392157,0.3627450980392157
Task1554ScitailClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.4724573671942093,,0.57,0.57
Task1624DisflQaQuestionYesnoClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.39117199391172,,0.52,0.52
Task102CommongenSentenceGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.1691768135374451,0.0
Task202MnliContradictionClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.16666666666666666,,0.3333333333333333,0.3333333333333333
Task362SpolinYesandPromptResponseSubClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.7395833333333333,,0.87,0.74
Task034WinograndeQuestionModificationObject,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.5022315134479044,0.0
Task349Squad2.0AnswerableUnanswerableQuestionClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.7477931904161412,,0.76,0.76
Task050MultircAnswerability,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.7613860358958398,,0.77,0.77
Task133WinowhyReasonPlausibilityDetection,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.6601791782514674,,0.67,0.67
Task642EsnliClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.2916666666666667,,0.32,0.32
Task970SherliicCausalRelationship,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.6587715776796468,,0.66,0.66
Task743EurlexSummarization,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.2154966249346,0.0
Task242TweetqaClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.9099189270343309,,0.91,0.91
Task620OhsumedMedicalSubjectHeadingsAnswerGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.0015384615384615385,0.0
Task1156BardAnalogicalReasoningTools,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.0,0.0
Task641EsnliClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.220264331627968,,0.35294117647058826,0.35294117647058826
Task1356XlsumTitleGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.11872221784152474,0.0
Task1158BardAnalogicalReasoningManipulatingItems,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.0,0.0
Task220RocstoriesTitleClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.9299369432489241,,0.93,0.93
Task935DefeasibleNliAtomicClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.37629937629937626,,0.52,0.52
Task1345GlueQqpQuestionParaprashing,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.1728848727561364,0.0
Task226EnglishLanguageAnswerRelevanceClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.696969696969697,,0.7,0.7
Task1659TitleGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.29393984459845124,0.0
Task760MsrSqaLongTextGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.3822561236641879,0.0
Task937DefeasibleNliSocialClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.39673982800667434,,0.53,0.53
Task957E2eNlgTextGenerationGenerate,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.3700341146567196,0.0
Task1344GlueEntailmentClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.7996794871794872,,0.8,0.8
Task892GapReverseCoreferenceResolution,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.1776607160277046,,0.5098039215686274,0.2647058823529412
Task1615SickTclassifyBRelationA,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.758784425451092,,0.9248366013071898,0.7745098039215687
Task828CopaCommonsenseCauseEffect,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.3333333333333333,,0.5,0.5
Task1358XlsumTitleGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.35383331496953085,0.0
Task1385AnliR1Entailment,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.3113470613470613,,0.38235294117647056,0.38235294117647056
Task418PersentTitleGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.1608357424962174,0.0
Task1586ScifactTitleGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.2605039950461057,0.0
Task890GcwdClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.30771361307298156,,0.38235294117647056,0.38235294117647056
Task640EsnliClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.20869990224828935,,0.37,0.37
Task1153BardAnalogicalReasoningAffordance,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.14666666666666667,0.14
Task1439DoqaCookingIsanswerable,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.7198879551820728,,0.72,0.72
Task290TellmewhyQuestionAnswerability,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.38557993730407525,,0.8366666666666667,0.51
Task1598NycLongTextGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.2260963459417751,0.0
Task1415YoutubeCaptionCorrectionsGrammarCorrection,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.5966158205267452,0.0
Task393PlausibleResultGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.17945444906543973,0.0
Task288GigawordSummarization,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.1842498551377655,0.0
Task1388CbEntailment,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.3481781376518218,,0.45,0.45
Task1154BardAnalogicalReasoningTravel,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.0,0.0
Task392InverseCausalRelationship,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.6567996567996568,,0.8933333333333334,0.68
Task879SchemaGuidedDstc8Classification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.742559983523839,,0.75,0.75
Task281PointsOfCorrespondence,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.16414887786656368,0.0
Task1442DoqaMoviesIsanswerable,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.6578099838969405,,0.66,0.66
Task613PolitifactTextGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.0,0.0
Task304NumericFusedHeadResolution,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.0,0.0
Task199MnliClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.3993993993993994,,0.44,0.44
Task330GapAnswerGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.19899999999999998,0.16
Task1394MetaWozTaskClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.0009118541033434651,,0.021739130434782608,0.021739130434782608
Task677OllieSentenceAnswerGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.2469171494822343,0.0
Task121ZestTextModification,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.24280548734679516,0.0
Task232IircLinkNumberClassification,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.3288590604026846,,0.49,0.49
Task500ScruplesAnecdotesTitleGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.06898739106810033,0.0
Task623OhsumedYesNoAnswerGeneration,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.9699729756781104,,0.97,0.97
Task1390WscfixedCoreference,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.5659722222222222,,0.6,0.6
Task1159BardAnalogicalReasoningContainers,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.0,0.0
Task614GlucoseCauseEventDetection,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.3411533199157026,0.0
Task1540ParsedPdfsSummarization,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.25196711928544746,0.0
Task602Wikitext-103AnswerGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.054052488849399595,0.0
Task1155BardAnalogicalReasoningTrashOrTreasure,clf,superni,ERROR,Meta-Llama-3-8B-Instruct,0.6510673234811166,,0.66,0.66
Task1631OpenpiAnswerGeneration,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.32522098033664165,0.0
Task036QascTopicWordToGenerateRelatedFact,gen,superni,ERROR,Meta-Llama-3-8B-Instruct,,,0.07100777000777002,0.0
Task1516ImppresNaturallanguageinference,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.3482569980979313,,0.4411764705882353,0.4411764705882353
Task1612SickLabelClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.7962174215195971,,0.7941176470588235,0.7941176470588235
Task1409DartTextGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.4047245077502608,0.0
Task035WinograndeQuestionModificationPerson,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.5083260171262733,0.0
Task1161Coda19TitleGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.3365121201641588,0.0
Task1557JflegAnswerGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.6415233290663208,0.0
Task200MnliEntailmentClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.8036297036297037,,0.803921568627451,0.803921568627451
Task391CausalRelationship,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.49286472461375164,,0.8566666666666669,0.57
Task1342AmazonUsReviewsTitle,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.11372396191774303,0.0
Task1533DailyDialogFormalClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.3551783129359126,,0.51,0.51
Task1531DailyDialogTypeClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.39168028322440085,,0.43,0.43
Task329GapClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.6613297150610583,,0.6666666666666666,0.6666666666666666
Task402GrailqaParaphraseGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.34678684986954494,0.0
Task1152BardAnalogicalReasoningCausation,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.265,0.23
Task670AmbigqaQuestionGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.37071519136464054,0.0
Task936DefeasibleNliSnliClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.7596153846153846,,0.76,0.76
Task190SnliClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.43899018232819076,,0.52,0.52
Task1407DartQuestionGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.29023892819233227,0.0
Task442ComQaParaphraseQuestionGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.46923769279409483,0.0
Task1622DisflQaTextModication,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.6725676839263888,0.08
Task1391WinograndeEasyAnswerGeneration,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.6601791782514674,,0.67,0.67
Task1529Scitail1.1Classification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.84998499849985,,0.85,0.85
Task1728WebNlgDataToText,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.48374521197429954,0.01
Task1195DisflqaDisfluentToFluentConversion,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.4505737589512653,0.0
Task510RedditTifuTitleSummarization,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.33459709655286735,0.0
Task033WinograndeAnswerGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.35682539682539677,0.23
Task671AmbigqaTextGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.3523549338205891,0.0
Task645Summarization,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.4506036186036185,0.0
Task1393SuperglueCopaTextCompletion,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.58,,0.58,0.58
Task893GapFillTheBlankCoreferenceResolution,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.16156347596509868,,0.27,0.22
Task219RocstoriesTitleAnswerGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.16540548340548342,0.0
Task769QedSummarization,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.4143707403707403,0.0
Task1387AnliR3Entailment,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.3202020202020202,,0.4117647058823529,0.4117647058823529
Task1534DailyDialogQuestionClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.6847414880201765,,0.7,0.7
Task249EnhancedWscPronounDisambiguation,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.25507886557886555,0.01
Task401NumericFusedHeadReference,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.13985714285714287,0.06
Task880SchemaGuidedDstc8Classification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.1438415159345392,,0.39666666666666656,0.25
Task020MctacoSpanBasedQuestion,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.0,,0.54,0.0
Task569RecipeNlgTextGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.29098156235585226,0.0
Task201MnliNeutralClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.19846474505617406,,0.23529411764705882,0.23529411764705882
Task1664WinobiasTextGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.46965306915306876,0.0
Task891GapCoreferenceResolution,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.0033333333333333335,0.0
Task738PerspectrumClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.8357963875205254,,0.84,0.84
Task648AnswerGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.15508630258630265,0.0
Task1640Aqa1.0AnswerableUnanswerableQuestionClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.7390606182256123,,0.74,0.74
Task233IircLinkExistsClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.4415954415954416,,0.51,0.51
Task520AquamuseAnswerGivenInPassage,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.9095568284594513,,0.91,0.91
Task619OhsumedAbstractTitleGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.3172884193382185,0.0
Task827CopaCommonsenseReasoning,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.8465473145780051,,0.85,0.85
Task1562ZestTextModification,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.3950912230389433,0.0
Task1157BardAnalogicalReasoningRoomsForContainers,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.14899999999999994,0.0
Task039QascFindOverlappingWords,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.0,0.0
Task1386AnliR2Entailment,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.291005291005291,,0.3627450980392157,0.3627450980392157
Task1554ScitailClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.8891017239641092,,0.89,0.89
Task1624DisflQaQuestionYesnoClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.4233836339099497,,0.53,0.53
Task102CommongenSentenceGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.24049575062794554,0.0
Task202MnliContradictionClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.2951251646903821,,0.39215686274509803,0.39215686274509803
Task362SpolinYesandPromptResponseSubClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.7253585596582239,,0.865,0.73
Task034WinograndeQuestionModificationObject,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.7165345448310906,0.0
Task349Squad2.0AnswerableUnanswerableQuestionClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.7960016319869441,,0.8,0.8
Task050MultircAnswerability,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.06243550051599587,,0.74,0.07
Task133WinowhyReasonPlausibilityDetection,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.7237851662404092,,0.73,0.73
Task642EsnliClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.39123376623376627,,0.4,0.4
Task970SherliicCausalRelationship,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.7189883580891208,,0.72,0.72
Task743EurlexSummarization,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.2715000025049747,0.0
Task242TweetqaClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.9399038461538461,,0.94,0.94
Task620OhsumedMedicalSubjectHeadingsAnswerGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.025444444444444447,0.0
Task1156BardAnalogicalReasoningTools,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.12300000000000001,0.0
Task641EsnliClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.4142578903103005,,0.43137254901960786,0.43137254901960786
Task1356XlsumTitleGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.23240759294776894,0.0
Task1158BardAnalogicalReasoningManipulatingItems,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.3240000000000002,0.07
Task220RocstoriesTitleClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.949874686716792,,0.95,0.95
Task935DefeasibleNliAtomicClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.7171717171717171,,0.72,0.72
Task1345GlueQqpQuestionParaprashing,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.24618061249334264,0.0
Task226EnglishLanguageAnswerRelevanceClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.4165398274987316,,0.54,0.54
Task1659TitleGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.3063990966279738,0.0
Task760MsrSqaLongTextGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.3970215833087793,0.0
Task937DefeasibleNliSocialClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.8599439775910365,,0.86,0.86
Task957E2eNlgTextGenerationGenerate,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.41625604390582366,0.0
Task1344GlueEntailmentClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.8286117552172598,,0.83,0.83
Task892GapReverseCoreferenceResolution,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.12585759841585975,,0.2647058823529412,0.21568627450980393
Task1615SickTclassifyBRelationA,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.6823529411764705,,0.8954248366013075,0.6862745098039216
Task828CopaCommonsenseCauseEffect,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.3333333333333333,,0.5,0.5
Task1358XlsumTitleGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.32098970908667357,0.0
Task1385AnliR1Entailment,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.3677156177156177,,0.46078431372549017,0.46078431372549017
Task418PersentTitleGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.26247528576613455,0.0
Task1586ScifactTitleGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.3230800691611163,0.0
Task890GcwdClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.2853558627752176,,0.39215686274509803,0.39215686274509803
Task640EsnliClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.29294883066643224,,0.39,0.39
Task1153BardAnalogicalReasoningAffordance,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.10833333333333332,0.02
Task1439DoqaCookingIsanswerable,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.508679986898133,,0.55,0.55
Task290TellmewhyQuestionAnswerability,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.5805626598465473,,0.8633333333333336,0.59
Task1598NycLongTextGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.2618885025678536,0.0
Task1415YoutubeCaptionCorrectionsGrammarCorrection,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.8331246593971516,0.0
Task393PlausibleResultGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.18596305494318974,0.0
Task288GigawordSummarization,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.2501294810274704,0.0
Task1388CbEntailment,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.3167092924126172,,0.37,0.37
Task1154BardAnalogicalReasoningTravel,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.15566666666666665,0.0
Task392InverseCausalRelationship,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.4106583072100314,,0.8433333333333336,0.53
Task879SchemaGuidedDstc8Classification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.6991389148251893,,0.71,0.71
Task281PointsOfCorrespondence,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.43775618691657725,0.0
Task1442DoqaMoviesIsanswerable,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.628178072555522,,0.63,0.63
Task613PolitifactTextGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.041167388167388165,0.0
Task304NumericFusedHeadResolution,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.08974192474192474,0.03
Task199MnliClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.41666666666666663,,0.44,0.44
Task330GapAnswerGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.26601010101010103,0.1
Task1394MetaWozTaskClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.6275902522263105,,0.6521739130434783,0.6376811594202898
Task677OllieSentenceAnswerGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.34974937889169977,0.0
Task121ZestTextModification,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.399960149871795,0.01
Task232IircLinkNumberClassification,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.4791666666666667,,0.5,0.5
Task500ScruplesAnecdotesTitleGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.15861372381461647,0.0
Task623OhsumedYesNoAnswerGeneration,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.949874686716792,,0.95,0.95
Task1390WscfixedCoreference,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.6683750376846548,,0.67,0.67
Task1159BardAnalogicalReasoningContainers,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.09666666666666666,0.0
Task614GlucoseCauseEventDetection,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.33597499068355013,0.0
Task1540ParsedPdfsSummarization,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.3279827713232526,0.0
Task602Wikitext-103AnswerGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.14420381206095487,0.0
Task1155BardAnalogicalReasoningTrashOrTreasure,clf,superni,ERROR,Mistral-7B-Instruct-v0.3,0.6666666666666666,,0.68,0.68
Task1631OpenpiAnswerGeneration,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.45041002693486726,0.0
Task036QascTopicWordToGenerateRelatedFact,gen,superni,ERROR,Mistral-7B-Instruct-v0.3,,,0.1505997890997891,0.0
